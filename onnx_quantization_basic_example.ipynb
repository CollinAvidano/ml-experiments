{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDuerpduD2GQ",
        "outputId": "fd08c5f0-b831-475b-bafb-cfe00ea30a9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  gdb libbabeltrace1 libc6-dbg libdebuginfod-common libdebuginfod1 libipt2\n",
            "  libsource-highlight-common libsource-highlight4v5\n",
            "Suggested packages:\n",
            "  gdb-doc gdbserver valgrind-dbg valgrind-mpi kcachegrind alleyoop valkyrie\n",
            "The following NEW packages will be installed:\n",
            "  gdb libbabeltrace1 libc6-dbg libdebuginfod-common libdebuginfod1 libipt2\n",
            "  libsource-highlight-common libsource-highlight4v5 valgrind\n",
            "0 upgraded, 9 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 32.3 MB of archives.\n",
            "After this operation, 111 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdebuginfod-common all 0.186-1build1 [7,878 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libbabeltrace1 amd64 1.5.8-2build1 [160 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdebuginfod1 amd64 0.186-1build1 [12.7 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libipt2 amd64 2.0.5-1 [46.4 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsource-highlight-common all 3.1.9-4.1build2 [64.5 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsource-highlight4v5 amd64 3.1.9-4.1build2 [207 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gdb amd64 12.1-0ubuntu1~22.04.2 [3,920 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libc6-dbg amd64 2.35-0ubuntu3.8 [13.8 MB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 valgrind amd64 1:3.18.1-1ubuntu2 [14.1 MB]\n",
            "Fetched 32.3 MB in 5s (7,122 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 9.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libdebuginfod-common.\n",
            "(Reading database ... 123599 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libdebuginfod-common_0.186-1build1_all.deb ...\n",
            "Unpacking libdebuginfod-common (0.186-1build1) ...\n",
            "Selecting previously unselected package libbabeltrace1:amd64.\n",
            "Preparing to unpack .../1-libbabeltrace1_1.5.8-2build1_amd64.deb ...\n",
            "Unpacking libbabeltrace1:amd64 (1.5.8-2build1) ...\n",
            "Selecting previously unselected package libdebuginfod1:amd64.\n",
            "Preparing to unpack .../2-libdebuginfod1_0.186-1build1_amd64.deb ...\n",
            "Unpacking libdebuginfod1:amd64 (0.186-1build1) ...\n",
            "Selecting previously unselected package libipt2.\n",
            "Preparing to unpack .../3-libipt2_2.0.5-1_amd64.deb ...\n",
            "Unpacking libipt2 (2.0.5-1) ...\n",
            "Selecting previously unselected package libsource-highlight-common.\n",
            "Preparing to unpack .../4-libsource-highlight-common_3.1.9-4.1build2_all.deb ...\n",
            "Unpacking libsource-highlight-common (3.1.9-4.1build2) ...\n",
            "Selecting previously unselected package libsource-highlight4v5.\n",
            "Preparing to unpack .../5-libsource-highlight4v5_3.1.9-4.1build2_amd64.deb ...\n",
            "Unpacking libsource-highlight4v5 (3.1.9-4.1build2) ...\n",
            "Selecting previously unselected package gdb.\n",
            "Preparing to unpack .../6-gdb_12.1-0ubuntu1~22.04.2_amd64.deb ...\n",
            "Unpacking gdb (12.1-0ubuntu1~22.04.2) ...\n",
            "Selecting previously unselected package libc6-dbg:amd64.\n",
            "Preparing to unpack .../7-libc6-dbg_2.35-0ubuntu3.8_amd64.deb ...\n",
            "Unpacking libc6-dbg:amd64 (2.35-0ubuntu3.8) ...\n",
            "Selecting previously unselected package valgrind.\n",
            "Preparing to unpack .../8-valgrind_1%3a3.18.1-1ubuntu2_amd64.deb ...\n",
            "Unpacking valgrind (1:3.18.1-1ubuntu2) ...\n",
            "Setting up libdebuginfod-common (0.186-1build1) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "\n",
            "Creating config file /etc/profile.d/debuginfod.sh with new version\n",
            "\n",
            "Creating config file /etc/profile.d/debuginfod.csh with new version\n",
            "Setting up libdebuginfod1:amd64 (0.186-1build1) ...\n",
            "Setting up libsource-highlight-common (3.1.9-4.1build2) ...\n",
            "Setting up libc6-dbg:amd64 (2.35-0ubuntu3.8) ...\n",
            "Setting up libipt2 (2.0.5-1) ...\n",
            "Setting up libbabeltrace1:amd64 (1.5.8-2build1) ...\n",
            "Setting up valgrind (1:3.18.1-1ubuntu2) ...\n",
            "Setting up libsource-highlight4v5 (3.1.9-4.1build2) ...\n",
            "Setting up gdb (12.1-0ubuntu1~22.04.2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.4.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.4.1+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.1->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.1->torchvision) (1.3.0)\n",
            "Collecting detectors\n",
            "  Downloading detectors-0.1.11-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from detectors) (10.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from detectors) (1.26.4)\n",
            "Collecting optuna (from detectors)\n",
            "  Downloading optuna-4.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from detectors) (1.3.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from detectors) (0.23.2)\n",
            "Collecting timm>=0.8.19.dev0 (from detectors)\n",
            "  Downloading timm-1.0.9-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m881.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.10/dist-packages (from detectors) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from detectors) (0.19.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from detectors) (4.66.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from detectors) (1.13.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from detectors) (0.34.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from detectors) (5.9.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from detectors) (2.1.4)\n",
            "Collecting wilds (from detectors)\n",
            "  Downloading wilds-2.0.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting faiss-cpu (from detectors)\n",
            "  Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from detectors) (3.7.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm>=0.8.19.dev0->detectors) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm>=0.8.19.dev0->detectors) (0.24.7)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm>=0.8.19.dev0->detectors) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->detectors) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->detectors) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->detectors) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->detectors) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->detectors) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->detectors) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->detectors) (24.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectors) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectors) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectors) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectors) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectors) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectors) (2.8.2)\n",
            "Collecting alembic>=1.5.0 (from optuna->detectors)\n",
            "  Downloading alembic-1.13.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna->detectors)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna->detectors) (2.0.35)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->detectors) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->detectors) (2024.1)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->detectors) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->detectors) (2024.8.30)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->detectors) (0.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->detectors) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->detectors) (3.5.0)\n",
            "Collecting ogb>=1.2.6 (from wilds->detectors)\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting outdated>=0.2.0 (from wilds->detectors)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna->detectors)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm>=0.8.19.dev0->detectors) (2.32.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.2.6->wilds->detectors) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.2.6->wilds->detectors) (2.0.7)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->wilds->detectors) (71.0.4)\n",
            "Collecting littleutils (from outdated>=0.2.0->wilds->detectors)\n",
            "  Downloading littleutils-0.2.4-py3-none-any.whl.metadata (679 bytes)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna->detectors) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.1->detectors) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.1->detectors) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm>=0.8.19.dev0->detectors) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm>=0.8.19.dev0->detectors) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm>=0.8.19.dev0->detectors) (2024.8.30)\n",
            "Downloading detectors-0.1.11-py3-none-any.whl (616 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.8/616.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm-1.0.9-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-4.0.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.8/362.8 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wilds-2.0.0-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.2/126.2 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Downloading littleutils-0.2.4-py3-none-any.whl (8.1 kB)\n",
            "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, littleutils, faiss-cpu, colorlog, outdated, alembic, optuna, ogb, wilds, timm, detectors\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.2 colorlog-6.8.2 detectors-0.1.11 faiss-cpu-1.8.0.post1 littleutils-0.2.4 ogb-1.3.6 optuna-4.0.0 outdated-0.2.2 timm-1.0.9 wilds-2.0.0\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (1.0.9)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.19.1+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.24.7)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n",
            "Collecting mlflow\n",
            "  Downloading mlflow-2.16.2-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting mlflow-skinny==2.16.2 (from mlflow)\n",
            "  Downloading mlflow_skinny-2.16.2-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.13.2)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.3-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7.1)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.26.4)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.1.4)\n",
            "Requirement already satisfied: pyarrow<18,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (14.0.2)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.3.2)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.13.1)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.35)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.4)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.16.2->mlflow) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.16.2->mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.16.2->mlflow) (2.2.1)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.16.2->mlflow)\n",
            "  Downloading databricks_sdk-0.32.3-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting gitpython<4,>=3.1.9 (from mlflow-skinny==2.16.2->mlflow)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.16.2->mlflow) (8.5.0)\n",
            "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==2.16.2->mlflow)\n",
            "  Downloading opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==2.16.2->mlflow)\n",
            "  Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.16.2->mlflow) (24.1)\n",
            "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.16.2->mlflow) (3.20.3)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.16.2->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.16.2->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.16.2->mlflow) (0.5.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.5)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker<8,>=4.0.0->mlflow) (2.0.7)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.0.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.4-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting aniso8601<10,>=8 (from graphene<4->mlflow)\n",
            "  Downloading aniso8601-9.0.1-py2.py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.0)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.10/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.2->mlflow) (2.27.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==2.16.2->mlflow)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.16.2->mlflow) (3.20.2)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.16.2->mlflow)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting importlib-metadata!=4.7.0,<9,>=3.7.0 (from mlflow-skinny==2.16.2->mlflow)\n",
            "  Downloading importlib_metadata-8.4.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.16.2->mlflow)\n",
            "  Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib<4->mlflow) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.16.2->mlflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.16.2->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.16.2->mlflow) (2024.8.30)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.16.2->mlflow) (1.16.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.16.2->mlflow)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.2->mlflow) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.2->mlflow) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.2->mlflow) (0.6.1)\n",
            "Downloading mlflow-2.16.2-py3-none-any.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-2.16.2-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.3-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.32.3-py3-none-any.whl (555 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m555.1/555.1 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.4-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.4.0-py3-none-any.whl (26 kB)\n",
            "Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: aniso8601, smmap, importlib-metadata, gunicorn, graphql-core, deprecated, opentelemetry-api, graphql-relay, gitdb, docker, opentelemetry-semantic-conventions, graphene, gitpython, databricks-sdk, opentelemetry-sdk, mlflow-skinny, mlflow\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.5.0\n",
            "    Uninstalling importlib_metadata-8.5.0:\n",
            "      Successfully uninstalled importlib_metadata-8.5.0\n",
            "Successfully installed aniso8601-9.0.1 databricks-sdk-0.32.3 deprecated-1.2.14 docker-7.1.0 gitdb-4.0.11 gitpython-3.1.43 graphene-3.3 graphql-core-3.2.4 graphql-relay-3.2.0 gunicorn-23.0.0 importlib-metadata-8.4.0 mlflow-2.16.2 mlflow-skinny-2.16.2 opentelemetry-api-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 smmap-5.0.1\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Downloading onnx-1.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.16.2\n",
            "Collecting onnxscript\n",
            "  Downloading onnxscript-0.1.0.dev20240920-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnxscript) (1.26.4)\n",
            "Requirement already satisfied: onnx>=1.16 in /usr/local/lib/python3.10/dist-packages (from onnxscript) (1.16.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from onnxscript) (4.12.2)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from onnxscript) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxscript) (24.1)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.16->onnxscript) (3.20.3)\n",
            "Downloading onnxscript-0.1.0.dev20240920-py3-none-any.whl (670 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.3/670.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnxscript\n",
            "Successfully installed onnxscript-0.1.0.dev20240920\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.13.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.19.2\n",
            "Collecting netron\n",
            "  Downloading netron-7.8.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Downloading netron-7.8.9-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: netron\n",
            "Successfully installed netron-7.8.9\n",
            "Collecting torch_tb_profiler\n",
            "  Downloading torch_tb_profiler-0.4.3-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from torch_tb_profiler) (2.1.4)\n",
            "Requirement already satisfied: tensorboard!=2.1.0,>=1.15 in /usr/local/lib/python3.10/dist-packages (from torch_tb_profiler) (2.17.0)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->torch_tb_profiler) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->torch_tb_profiler) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->torch_tb_profiler) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->torch_tb_profiler) (2024.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.1.0,>=1.15->torch_tb_profiler) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.1.0,>=1.15->torch_tb_profiler) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.1.0,>=1.15->torch_tb_profiler) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.1.0,>=1.15->torch_tb_profiler) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.1.0,>=1.15->torch_tb_profiler) (71.0.4)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.1.0,>=1.15->torch_tb_profiler) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.1.0,>=1.15->torch_tb_profiler) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.1.0,>=1.15->torch_tb_profiler) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard!=2.1.0,>=1.15->torch_tb_profiler) (2.1.5)\n",
            "Downloading torch_tb_profiler-0.4.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_tb_profiler\n",
            "Successfully installed torch_tb_profiler-0.4.3\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.4.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.5)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2024.6.1)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
            "  Downloading torchmetrics-1.4.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.12.2)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning)\n",
            "  Downloading lightning_utilities-0.11.7-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.10.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (71.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.4)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics>=0.7.0->pytorch-lightning) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.1.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.10)\n",
            "Downloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.7-py3-none-any.whl (26 kB)\n",
            "Downloading torchmetrics-1.4.2-py3-none-any.whl (869 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.2/869.2 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, pytorch-lightning\n",
            "Successfully installed lightning-utilities-0.11.7 pytorch-lightning-2.4.0 torchmetrics-1.4.2\n"
          ]
        }
      ],
      "source": [
        "!sudo apt install valgrind\n",
        "\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install detectors\n",
        "!pip install timm\n",
        "\n",
        "!pip install mlflow\n",
        "\n",
        "!pip install onnx\n",
        "!pip install onnxscript\n",
        "!pip install onnxruntime\n",
        "!pip install netron\n",
        "\n",
        "!pip install torch_tb_profiler\n",
        "!pip install pytorch-lightning\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqgWzTxY6Spd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2df6200c-fffc-4ac1-a49a-db4aea68386b",
        "cellView": "form"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter MLflow uri: http://mlflow.cavidano.com\n",
            "Enter your MLflow username: collin\n",
            "Enter your MLflow password: ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/09/20 23:49:01 INFO mlflow.tracking.fluent: Experiment with name 'onnx_quantization_test5' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mlflow-artifacts:/6/d4f50522faa44b47a9e727b35e39ae2e/artifacts\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/09/20 23:49:04 INFO mlflow.tracking._tracking_service.client: 🏃 View run languid-gull-863 at: http://mlflow.cavidano.com/#/experiments/6/runs/d4f50522faa44b47a9e727b35e39ae2e.\n",
            "2024/09/20 23:49:04 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow.cavidano.com/#/experiments/6.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mlflow-artifacts:/6/138583dac56e4334879a806fd0ad3e46/artifacts\n",
            "mlflow-artifacts:/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/09/20 23:49:07 INFO mlflow.tracking._tracking_service.client: 🏃 View run sedate-bass-999 at: http://mlflow.cavidano.com/#/experiments/6/runs/138583dac56e4334879a806fd0ad3e46.\n",
            "2024/09/20 23:49:07 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow.cavidano.com/#/experiments/6.\n"
          ]
        }
      ],
      "source": [
        "#@title MLFlow Tracking Auth\n",
        "import mlflow\n",
        "import os\n",
        "from getpass import getpass\n",
        "import configparser\n",
        "from google.colab import userdata\n",
        "\n",
        "def load_env_from_file(path:str):\n",
        "  # Create a ConfigParser object\n",
        "  config = configparser.ConfigParser()\n",
        "\n",
        "  # Read the INI file\n",
        "  config.read(path)\n",
        "\n",
        "  # Iterate over sections and keys to set environment variables\n",
        "  for section in config.sections():\n",
        "    for key, value in config.items(section):\n",
        "      # Set each key-value pair as an environment variable\n",
        "      os.environ[key.upper()] = value\n",
        "\n",
        "# MLFlow auth\n",
        "mlflow_auth_path = 'mlflow_auth.ini'\n",
        "if os.path.exists(mlflow_auth_path):\n",
        "  load_env_from_file(mlflow_auth_path)\n",
        "else:\n",
        "  try:\n",
        "    os.environ['MLFLOW_TRACKING_URI'] = userdata.get('MLFLOW_TRACKING_URI')\n",
        "    os.environ['MLFLOW_TRACKING_USERNAME'] = userdata.get('MLFLOW_TRACKING_USERNAME')\n",
        "    os.environ['MLFLOW_TRACKING_PASSWORD'] = userdata.get('MLFLOW_TRACKING_PASSWORD')\n",
        "  except userdata.SecretNotFoundError:\n",
        "    os.environ['MLFLOW_TRACKING_URI'] = input('Enter MLflow uri: ')\n",
        "    os.environ['MLFLOW_TRACKING_USERNAME'] = input('Enter your MLflow username: ')\n",
        "    os.environ['MLFLOW_TRACKING_PASSWORD'] = getpass('Enter your MLflow password: ')\n",
        "    # now proxied\n",
        "    # os.environ['AWS_ACCESS_KEY_ID'] = input('Enter your s3 compatible Identity: ')\n",
        "    # os.environ['AWS_SECRET_ACCESS_KEY'] = getpass('Enter your s3 compatible Key: ')\n",
        "\n",
        "mlflow.set_tracking_uri(os.environ['MLFLOW_TRACKING_URI'])\n",
        "\n",
        "experiment = mlflow.set_experiment(\"onnx_quantization_test5\")\n",
        "\n",
        "print(mlflow.get_artifact_uri())\n",
        "\n",
        "mlflow.end_run()\n",
        "with mlflow.start_run():\n",
        "  print(mlflow.get_artifact_uri())\n",
        "  print(experiment.artifact_location)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "uNTd8gR1EkNz"
      },
      "outputs": [],
      "source": [
        "#@title Wrapper for calibration data loader so onnx can use it\n",
        "\n",
        "#add work dir to args later rely on user to handle cleanup\n",
        "import torch\n",
        "import onnx\n",
        "import onnxruntime as ort\n",
        "from onnxruntime import quantization\n",
        "import numpy as np\n",
        "\n",
        "# Wrapper for calibration data loader so onnx can use it\n",
        "class QuantizationDataReader(quantization.CalibrationDataReader):\n",
        "  def __init__(self, torch_dl, input_name):\n",
        "    self.torch_dl = torch_dl\n",
        "    self.input_name = input_name\n",
        "    self.datasize = len(self.torch_dl)\n",
        "    self.enum_data = iter(self.torch_dl)\n",
        "\n",
        "  def to_numpy(self, pt_tensor):\n",
        "    return pt_tensor.detach().cpu().numpy() if pt_tensor.requires_grad else pt_tensor.cpu().numpy()\n",
        "\n",
        "  def get_next(self):\n",
        "    batch = next(self.enum_data, None)\n",
        "    if batch is not None:\n",
        "      return {self.input_name: self.to_numpy(batch[0])}\n",
        "    else:\n",
        "      return None\n",
        "\n",
        "  def rewind(self):\n",
        "    self.enum_data = iter(self.torch_dl)\n",
        "\n",
        "def onnx_convert(model_pt, output_path, torch_input:torch.tensor, training=False)-> None:\n",
        "  # if it contains batch norms double check they arent causing accuracy issues at eval time.\n",
        "  #If so run this in training mode\n",
        "\n",
        "  torch.onnx.export(model_pt,\n",
        "                    torch_input,\n",
        "                    output_path,\n",
        "                    export_params=True,\n",
        "                    opset_version=14,\n",
        "                    do_constant_folding=(not training),\n",
        "                    training=(torch.onnx.TrainingMode.TRAINING if training else torch.onnx.TrainingMode.Eval),\n",
        "                    input_names = ['input'],\n",
        "                    output_names = ['output'],\n",
        "                    dynamic_axes={'input' : {0 : 'batch_size'},\n",
        "                                  'output' : {0 : 'batch_size'}})\n",
        "\n",
        "def onnx_quantize(init_model_path:str, model_name:str, calibration_data_loader:torch.utils.data.DataLoader)->str:\n",
        "  ort_provider = ['CUDAExecutionProvider'] if torch.cuda.is_available() else ['CPUExecutionProvider']\n",
        "  ort_sess = ort.InferenceSession(init_model_path, providers=ort_provider)\n",
        "\n",
        "  # load and preprocess\n",
        "  model_onnx = onnx.load(init_model_path)\n",
        "  onnx.checker.check_model(model_onnx)\n",
        "  model_prep_path = f'{model_name}_prep.onnx'\n",
        "  quantization.shape_inference.quant_pre_process(init_model_path, model_prep_path, skip_symbolic_shape=False)\n",
        "\n",
        "  qdr = QuantizationDataReader(calibration_data_loader, input_name=ort_sess.get_inputs()[0].name)\n",
        "\n",
        "  # actual quantization\n",
        "  model_int8_path = f'{model_name}_int8.onnx'\n",
        "  q_static_opts = {\"ActivationSymmetric\": torch.cuda.is_available(), \"WeightSymmetric\":True}\n",
        "  quantization.quantize_static(model_input=model_prep_path,\n",
        "                                                model_output=model_int8_path,\n",
        "                                                calibration_data_reader=qdr,\n",
        "                                                extra_options=q_static_opts)\n",
        "  return model_int8_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64gyn_SyE6J4",
        "outputId": "36a5f364-a405-46b4-d43b-a89f26b3d312"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:10<00:00, 16278068.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ],
      "source": [
        "#@title Torch setup\n",
        "import torch\n",
        "from torch import optim, nn,  utils, Tensor\n",
        "from itertools import repeat\n",
        "from torchsummary import summary\n",
        "from torchvision import models, transforms\n",
        "import torchvision\n",
        "\n",
        "batch_size = 128\n",
        "dataset = torchvision.datasets.CIFAR10(root=\"./data\", download=True, transform=transforms.ToTensor())\n",
        "calib_ds, test_ds = torch.utils.data.random_split(dataset, [0.5, 0.5])\n",
        "\n",
        "# shortening test_ds again\n",
        "test_ds = torch.utils.data.Subset(test_ds, range(0, 1000))\n",
        "\n",
        "calibration_data_loader = utils.data.DataLoader(calib_ds, batch_size=batch_size, shuffle=False)\n",
        "test_data_loader = utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ducBYzTDDyWQ",
        "outputId": "ff39a38e-c6bf-4107-9dbc-24a3a9adafe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://huggingface.co/edadaltocg/resnet18_cifar10/resolve/main/pytorch_model.bin\" to /root/.cache/torch/hub/checkpoints/resnet18_cifar10.pth\n",
            "100%|██████████| 42.7M/42.7M [00:03<00:00, 13.1MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:668: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'bn1.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:350.)\n",
            "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:668: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'layer1.0.bn1.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:350.)\n",
            "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:668: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'layer1.0.bn2.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:350.)\n",
            "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:668: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'layer1.1.bn1.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:350.)\n",
            "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:668: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'layer1.1.bn2.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:350.)\n",
            "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:668: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'layer2.0.bn1.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:350.)\n",
            "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:668: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'layer2.0.bn2.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:350.)\n",
            "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:668: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'layer2.0.downsample.1.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:350.)\n",
            "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:668: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'layer2.1.bn1.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:350.)\n",
            "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:668: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'layer2.1.bn2.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:350.)\n",
            "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:668: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'layer3.0.bn1.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:350.)\n",
            "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:668: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'layer3.0.bn2.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:350.)\n",
            "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:668: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'layer3.0.downsample.1.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:350.)\n",
            "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:668: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'layer3.1.bn1.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:350.)\n",
            "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:668: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'layer3.1.bn2.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:350.)\n",
            "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:668: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'layer4.0.bn1.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:350.)\n",
            "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:668: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'layer4.0.bn2.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:350.)\n",
            "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:668: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'layer4.0.downsample.1.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:350.)\n",
            "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:668: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'layer4.1.bn1.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:350.)\n",
            "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:668: UserWarning: ONNX Preprocess - Removing mutation from node aten::add_ on block input: 'layer4.1.bn2.num_batches_tracked'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:350.)\n",
            "  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n"
          ]
        }
      ],
      "source": [
        "#@title Model download and quantization\n",
        "# https://huggingface.co/edadaltocg/resnet18_cifar10\n",
        "import detectors\n",
        "import timm\n",
        "model = timm.create_model(\"resnet18_cifar10\", pretrained=True)\n",
        "\n",
        "#I NEED TO FIX THIS IT SHOULD BE ABLE TO WORK WITHOUT BEING IN TRAIN MODE\n",
        "# dont remember how fixed this conversion?.... but batchnorm used to be causing an issue...\n",
        "# OH THATS RIGHT HAD TO PUT IT IN TRAIN MODE WHICH IS NOT RIGHTHA yeahhhh\n",
        "\n",
        "# nuke batchnorm from orbit\n",
        "# hoping if onnx has no value for these it will fallback to per batch norms just like pytorch itself will\n",
        "# def stop(m):\n",
        "#   if isinstance(m, nn.BatchNorm2d):\n",
        "#     m.track_running_stats = False\n",
        "#     m.running_mean = None\n",
        "#     m.running_var = None\n",
        "# model.eval()\n",
        "# model.apply(lambda m: stop(m))\n",
        "\n",
        "\n",
        "# Thats Fun...\n",
        "# UserWarning: ONNX export mode is set to TrainingMode.EVAL, but operator 'batch_norm' is set to train=True. Exporting with train=True.\n",
        "\n",
        "# pretrained via model method\n",
        "# model = torch.hub.load(\"pytorch/vision\", \"resnet18\", weights=\"IMAGENET1K_V1\")\n",
        "# model.eval()\n",
        "\n",
        "converted_model_path = \"onnx_res18.onnx\"\n",
        "torch_input = torch.randn(batch_size, 3, 32, 32) # has to match dataset and of course model\n",
        "onnx_convert(model, converted_model_path, torch_input, training=True)\n",
        "\n",
        "onnx_q_model_path = onnx_quantize(converted_model_path, \"resnet18\", calibration_data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnWob8eAbJ5R"
      },
      "outputs": [],
      "source": [
        "def to_numpy(tensor):\n",
        "  return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWiuGITDFuym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39078fc6-1061-4315-e61f-7c3eb13fbddd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/09/21 00:03:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function print>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#@title reload and log onnx models BROKEN\n",
        "# have to log from an onnx object and conversion and quantization always gives paths so have to reload...\n",
        "# mlflow.end_run()\n",
        "\n",
        "onnx_model = onnx.load(converted_model_path)\n",
        "onnx_q_model = onnx.load(onnx_q_model_path)\n",
        "\n",
        "import logging\n",
        "logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)\n",
        "np_in = to_numpy(torch_input)\n",
        "\n",
        "mlflow.onnx.log_model(onnx_model, \"mlflow-artifacts:/onnx_res18.onnx\")\n",
        "mlflow.onnx.log_model(onnx_q_model, \"mlflow-artifacts:/onnx_res18_int8.onnx\")\n",
        "\n",
        "# mlflow.onnx.save_model(onnx_model, \"onnx_res18.onnx\")\n",
        "# mlflow.onnx.save_model(onnx_q_model, \"onnx_res18_int8.onnx\")\n",
        "\n",
        "# mlflow.onnx.log_model(onnx_model, \"onnx_res18.onnx\")\n",
        "\n",
        "# mlflow.onnx.log_model(onnx_model, \"onnx_res18.onnx\", input_example = np_in)\n",
        "# mlflow.onnx.log_model(onnx_q_model, \"onnx_res18_int8.onnx\", input_example = np_in)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LdBhBYWYTuE"
      },
      "outputs": [],
      "source": [
        "#@title load onnx models from registry BROKEN\n",
        "# should save to same file names\n",
        "converted_model_path = \"onnx_res18.onnx\"\n",
        "onnx_q_model_path = \"onnx_res18_int8.onnx\"\n",
        "\n",
        "# pretty sure I need run ids for this to work\n",
        "mlflow.onnx.load_model(\"mlflow-artifacts:/onnx_res18.onnx\", dst_path=\"./\")\n",
        "mlflow.onnx.load_model(\"mlflow-artifacts:/onnx_res18_int8.onnx\", dst_path=\"./\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZVGSw0VDwFS"
      },
      "outputs": [],
      "source": [
        "#@title Eval code onnx model inits and helpers\n",
        "\n",
        "def run_pytorch(model, data):\n",
        "  return model(data)\n",
        "\n",
        "def run_onnx(session, data):\n",
        "  ort_inputs = {session.get_inputs()[0].name: to_numpy(data)}\n",
        "  return session.run(None, ort_inputs)[0]\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  model.to('cuda')\n",
        "model.eval()\n",
        "\n",
        "ort_provider = ['CUDAExecutionProvider'] if torch.cuda.is_available() else ['CPUExecutionProvider']\n",
        "ort_converted_sess = ort.InferenceSession(converted_model_path, providers=ort_provider)\n",
        "ort_quantized_sess = ort.InferenceSession(onnx_q_model_path, providers=ort_provider)\n",
        "\n",
        "num_threads = torch.get_num_threads()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "e7fVs7wl7V1Z"
      },
      "outputs": [],
      "source": [
        "#@title COMPARE ALL FORMS ACCURACY\n",
        "from tqdm import tqdm\n",
        "\n",
        "correct_pt = 0\n",
        "correct_converted_onnx = 0\n",
        "correct_quantized_onnx = 0\n",
        "pt_to_conv_tot_abs_error = 0\n",
        "conv_to_quant_tot_abs_error = 0\n",
        "\n",
        "for img_batch, label_batch in tqdm(test_data_loader, ascii=True, unit=\"batches\"):\n",
        "\n",
        "  # pytorch\n",
        "  if torch.cuda.is_available():\n",
        "    img_batch = img_batch.to('cuda')\n",
        "    label_batch = label_batch.to('cuda')\n",
        "\n",
        "  with torch.no_grad():\n",
        "    pt_outs = model(img_batch)\n",
        "\n",
        "  pt_preds = torch.argmax(pt_outs, dim=1)\n",
        "  correct_pt += torch.sum(pt_preds == label_batch)\n",
        "\n",
        "  # converted\n",
        "  ort_converted_outs = run_onnx(ort_converted_sess, img_batch)\n",
        "  ort_preds = np.argmax(ort_converted_outs, axis=1)\n",
        "  correct_converted_onnx += np.sum(np.equal(ort_preds, to_numpy(label_batch)))\n",
        "\n",
        "  # quantized\n",
        "  ort_quantized_outs = run_onnx(ort_quantized_sess, img_batch)\n",
        "  ort_preds = np.argmax(ort_quantized_outs, axis=1)\n",
        "  correct_quantized_onnx += np.sum(np.equal(ort_preds, to_numpy(label_batch)))\n",
        "\n",
        "  # abs errors\n",
        "  pt_to_conv_tot_abs_error += np.sum(np.abs(to_numpy(pt_outs - ort_converted_outs)))\n",
        "  conv_to_quant_tot_abs_error += np.sum(np.abs(ort_converted_outs - ort_quantized_outs))\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "print(f\"pytorch   top-1 acc = {100.0 * correct_pt/len(test_ds)} with {correct_pt} correct samples\")\n",
        "print(f\"converted top-1 acc = {100.0 * correct_converted_onnx/len(test_ds)} with {correct_converted_onnx} correct samples\")\n",
        "print(f\"quantized top-1 acc = {100.0 * correct_quantized_onnx/len(test_ds)} with {correct_quantized_onnx} correct samples\")\n",
        "\n",
        "mae = pt_to_conv_tot_abs_error/(len(test_ds))\n",
        "print(f\"pt_to_conv: mean abs error = {mae} with total abs error {pt_to_conv_tot_abs_error}\")\n",
        "\n",
        "mae = conv_to_quant_tot_abs_error/(len(test_ds))\n",
        "print(f\"conv_to_quant: mean abs error = {mae} with total abs error {conv_to_quant_tot_abs_error}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEt9Bh4O_aNt"
      },
      "outputs": [],
      "source": [
        "#@title timing with torch.benchmark\n",
        "import torch.utils.benchmark as benchmark\n",
        "\n",
        "results = []\n",
        "label = \"Average Inference Times\"\n",
        "\n",
        "num_runs = 100\n",
        "batch_sizes = [1, 64, 128, 512]\n",
        "batch_sizes = [32]\n",
        "\n",
        "# def run_pytorch(model, data):\n",
        "#   return model(data)\n",
        "\n",
        "# def run_onnx(session, data):\n",
        "#   ort_inputs = {session.get_inputs()[0].name: data}\n",
        "#   return session.run(None, ort_inputs)[0]\n",
        "\n",
        "\n",
        "def timing(t):\n",
        "  # return t.timeit(num_runs)\n",
        "  return t.blocked_autorange(min_run_time=4)\n",
        "\n",
        "with mlflow.start_run():\n",
        "  for batch_size in batch_sizes:\n",
        "    mlflow.log_param(\"batch_size\", batch_size)\n",
        "    data = torch.randn((batch_size, 3, 32, 32))\n",
        "    np_data = to_numpy(data)\n",
        "\n",
        "    sub_label = f\"Batch Size: {batch_size}\"\n",
        "\n",
        "    # pytorch\n",
        "    t = benchmark.Timer(\n",
        "      stmt = 'run_pytorch(model, data)',\n",
        "      setup = 'from __main__ import run_pytorch',\n",
        "      globals={'model': model, 'data': data},\n",
        "      num_threads=num_threads,\n",
        "      label=label,\n",
        "      sub_label=sub_label,\n",
        "      description=\"Pytorch\",\n",
        "    )\n",
        "    results.append(timing(t))\n",
        "    mlflow.log_metric(\"time\", str(results[-1]))\n",
        "\n",
        "    # converted\n",
        "    t = benchmark.Timer(\n",
        "      stmt = 'run_onnx(session, data)',\n",
        "      setup = 'from __main__ import run_onnx',\n",
        "      globals={'session': ort_converted_sess, 'data': data},\n",
        "      num_threads=num_threads,\n",
        "      label=label,\n",
        "      sub_label=sub_label,\n",
        "      description=\"Onnx Converted\",\n",
        "    )\n",
        "    results.append(timing(t))\n",
        "    mlflow.log_metric(\"time\", str(results[-1]))\n",
        "\n",
        "    # quantized\n",
        "    t = benchmark.Timer(\n",
        "      stmt = 'run_onnx(session, data)',\n",
        "      setup = 'from __main__ import run_onnx',\n",
        "      globals={'session': ort_quantized_sess, 'data': data},\n",
        "      num_threads=num_threads,\n",
        "      label=label,\n",
        "      sub_label=sub_label,\n",
        "      description=\"Onnx Quantized\"\n",
        "    )\n",
        "    results.append(timing(t))\n",
        "    mlflow.log_metric(\"time\", str(results[-1]))\n",
        "\n",
        "  compare = benchmark.Compare(results)\n",
        "  compare.print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOJlrzVv5UuI"
      },
      "outputs": [],
      "source": [
        "#@title timing with perf_counter\n",
        "import time\n",
        "\n",
        "results = []\n",
        "num_runs = 100\n",
        "batch_size = 32\n",
        "data = torch.zeros((batch_size, 3, 32, 32))\n",
        "\n",
        "def perf_benchmark(model, input_data, eval_func, num_runs=num_runs):\n",
        "    times = []\n",
        "    for _ in range(num_runs):\n",
        "        start = time.perf_counter()\n",
        "        eval_func(model, input_data)\n",
        "        end = time.perf_counter()\n",
        "        times.append(end - start)\n",
        "    return np.mean(times), np.std(times)\n",
        "\n",
        "print(\"perf_counter\")\n",
        "print(\"pytorch\")\n",
        "mean, std = perf_benchmark(model, data, run_pytorch)\n",
        "print('mean: {}ms, std: {}ms'.format(mean * 1000, std * 1000))\n",
        "\n",
        "print(\"converted\")\n",
        "mean, std = perf_benchmark(ort_converted_sess, data, run_onnx)\n",
        "print('mean: {}ms, std: {}ms'.format(mean * 1000, std * 1000))\n",
        "\n",
        "print(\"quantized\")\n",
        "mean, std = perf_benchmark(ort_quantized_sess, data, run_onnx)\n",
        "print('mean: {}ms, std: {}ms'.format(mean * 1000, std * 1000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APP3EegoCgwZ"
      },
      "outputs": [],
      "source": [
        "#@title callgrind collection with torch.benchmark\n",
        "import os\n",
        "\n",
        "results = []\n",
        "label = \"Average Inference Times\"\n",
        "\n",
        "num_runs = 100\n",
        "batch_sizes = [1, 64, 128, 512]\n",
        "# batch_sizes = [1]\n",
        "\n",
        "def timing(t):\n",
        "  return t.collect_callgrind()\n",
        "\n",
        "for batch_size in batch_sizes:\n",
        "  data = torch.randn((batch_size, 3, 32, 32))\n",
        "  np_data = to_numpy(data)\n",
        "  sub_label = f\"Batch Size: {batch_size}\"\n",
        "\n",
        "  # pytorch\n",
        "  t = benchmark.Timer(\n",
        "    stmt = 'run_pytorch(model, data)',\n",
        "    setup = 'from __main__ import run_pytorch',\n",
        "    globals={'model': model, 'data': data},\n",
        "    num_threads=num_threads,\n",
        "    label=label,\n",
        "    sub_label=sub_label,\n",
        "    description=\"Pytorch\",\n",
        "  )\n",
        "  results.append(timing(t))\n",
        "\n",
        "  # converted\n",
        "  t = benchmark.Timer(\n",
        "    stmt = 'run_onnx(session, data)',\n",
        "    setup = 'from __main__ import run_onnx',\n",
        "    globals={'session': ort_converted_sess, 'data': np_data},\n",
        "    num_threads=num_threads,\n",
        "    label=label,\n",
        "    sub_label=sub_label,\n",
        "    description=\"Onnx Converted\",\n",
        "  )\n",
        "  results.append(timing(t))\n",
        "\n",
        "  # quantized\n",
        "  t = benchmark.Timer(\n",
        "    stmt = 'run_onnx(session, data)',\n",
        "    setup = 'from __main__ import run_onnx',\n",
        "    globals={'session': ort_quantized_sess, 'data': np_data},\n",
        "    num_threads=num_threads,\n",
        "    label=label,\n",
        "    sub_label=sub_label,\n",
        "    description=\"Onnx Quantized\"\n",
        "  )\n",
        "  results.append(timing(t))\n",
        "\n",
        "for result in results:\n",
        "  print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFC_B6XixyYn"
      },
      "outputs": [],
      "source": [
        "#@title torch profiler\n",
        "import torch.profiler\n",
        "\n",
        "batch_size = 32\n",
        "data = torch.zeros((batch_size, 3, 32, 32))\n",
        "\n",
        "with torch.profiler.profile(\n",
        "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=1),\n",
        "        record_shapes=True,\n",
        "        profile_memory=True,\n",
        "        with_stack=True\n",
        ") as prof:\n",
        "  for i in range(5):\n",
        "    run_pytorch(model, data)\n",
        "    prof.step()\n",
        "\n",
        "  print(prof.key_averages().table(row_limit=-1))\n",
        "  # print(prof.key_averages().table(sort_by=\"self_cuda_time_total\", row_limit=-1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BC7O0BWW06l6"
      },
      "outputs": [],
      "source": [
        "#@title onnx profiler\n",
        "import onnxruntime as rt\n",
        "import json\n",
        "import pprint\n",
        "\n",
        "\n",
        "options = rt.SessionOptions()\n",
        "options.enable_profiling = True\n",
        "\n",
        "ort_provider = ['CUDAExecutionProvider'] if torch.cuda.is_available() else ['CPUExecutionProvider']\n",
        "\n",
        "batch_size = 32\n",
        "data = torch.zeros((batch_size, 3, 32, 32))\n",
        "\n",
        "ort_converted_sess = ort.InferenceSession(onnx_q_model_path, sess_options=options, providers=ort_provider)\n",
        "run_onnx(ort_converted_sess, data)\n",
        "profile_file = ort_converted_sess.end_profiling()\n",
        "print(\"converted\")\n",
        "print(profile_file)\n",
        "# with open(profile_file, 'r') as f:\n",
        "#   pprint.pp(json.load(f))\n",
        "\n",
        "\n",
        "ort_quantized_sess = ort.InferenceSession(onnx_q_model_path, sess_options=options, providers=ort_provider)\n",
        "run_onnx(ort_quantized_sess, data)\n",
        "profile_file = ort_quantized_sess.end_profiling()\n",
        "print(\"quantized\")\n",
        "print(profile_file)\n",
        "# with open(profile_file, 'r') as f:\n",
        "#   pprint.pp(json.load(f))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHlc5Y76Ed5A"
      },
      "outputs": [],
      "source": [
        "# netron viewer\n",
        "import os\n",
        "import torch\n",
        "import netron\n",
        "import portpicker\n",
        "from google.colab import output\n",
        "\n",
        "# model should come from another block\n",
        "# output_path = \"/content/output.pth\"\n",
        "# torch.save(model.state_dict(), output_path)\n",
        "output_path = converted_model_path\n",
        "port = portpicker.pick_unused_port()\n",
        "\n",
        "# Read the model file and start the netron browser.\n",
        "with output.temporary():\n",
        "  netron.start(output_path, port, browse=True)\n",
        "\n",
        "output.serve_kernel_port_as_iframe(port, height='800')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}