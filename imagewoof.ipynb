{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGMIYkLLzEY-",
        "outputId": "0e275243-1452-404a-b938-e7818ef5cae0"
      },
      "outputs": [],
      "source": [
        "!pip install huggingface_hub datasets detectors\n",
        "!pip install mlflow\n",
        "!pip install torch torchinfo torchvision pytorch-lightning optuna\n",
        "!pip install timm\n",
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_RV1RCfbUYV"
      },
      "outputs": [],
      "source": [
        "#@title Common Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch import utils\n",
        "from torch.utils.data import DataLoader\n",
        "from torchsummary import summary\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "from torchvision import transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "4QBRIkPlbSl4",
        "outputId": "2c030928-bba7-4a6b-fe68-5005b64a3f37"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'mlflow'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0afe0a2a4287>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#@title MLFlow Auth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mlflow'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#@title MLFlow Tracking Auth\n",
        "import mlflow\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# MLFlow auth\n",
        "if 'MLFLOW_TRACKING_URI' not in os.environ:\n",
        "    from google.colab import userdata\n",
        "    os.environ['MLFLOW_TRACKING_URI'] = userdata.get('MLFLOW_TRACKING_URI')\n",
        "    os.environ['MLFLOW_TRACKING_USERNAME'] = userdata.get('MLFLOW_TRACKING_USERNAME')\n",
        "    os.environ['MLFLOW_TRACKING_PASSWORD'] = userdata.get('MLFLOW_TRACKING_PASSWORD')\n",
        "  except (userdata.SecretNotFoundError, ImportError):\n",
        "    os.environ['MLFLOW_TRACKING_URI'] = input('Enter MLflow uri: ')\n",
        "    os.environ['MLFLOW_TRACKING_USERNAME'] = input('Enter your MLflow username: ')\n",
        "    os.environ['MLFLOW_TRACKING_PASSWORD'] = getpass('Enter your MLflow password: ')\n",
        "\n",
        "if 'MLFLOW_TRACKING_URI' in os.environ:\n",
        "    mlflow.set_tracking_uri(os.environ['MLFLOW_TRACKING_URI'])\n",
        "\n",
        "    experiment = mlflow.set_experiment(\"imagewoof_test\")\n",
        "\n",
        "    print(mlflow.get_artifact_uri())\n",
        "\n",
        "    mlflow.end_run()\n",
        "    with mlflow.start_run():\n",
        "        print(mlflow.get_artifact_uri())\n",
        "        print(experiment.artifact_location)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvnrjLijWZMr",
        "outputId": "f061a758-da49-4a7e-c638-3b0f78e5ad98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "#@title HF auth\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "import os\n",
        "\n",
        "os.environ['HF_TOKEN'] = userdata.get('HF_TOKEN')\n",
        "login(token=userdata.get('HF_TOKEN'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "bf965af15b4540049a0136112bc4d6a9",
            "a473a9f1f97d46edb4b03d59bc7ddcbc",
            "692c08edb4fb47daa928333a50452747",
            "12a63937f13b48039d0949d5f24bdf78",
            "575b38b944174b0ea8ad75633d1de0f6",
            "96c63041ebfd47118e747266da8f708d",
            "f38b94eea8d14a5d9f572d3679fe9c22",
            "8ab2310968034466934cabc25cc9eb2f",
            "76e78c7c7cd2474389110a11aea7dd5a",
            "411ee8783f234898b1306a3d11739009",
            "8d2f6fc0d13540efac5714f4e58bcfe1"
          ]
        },
        "id": "9Vsuw0nhe9ey",
        "outputId": "b271273d-d01f-46e8-faf2-0c0eb381b28c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf965af15b4540049a0136112bc4d6a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Model download\n",
        "import timm\n",
        "\n",
        "model_name = 'timm/vit_large_patch16_224'\n",
        "model = timm.create_model(model_name, pretrained=True, num_classes=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpsUusfNWKv3"
      },
      "outputs": [],
      "source": [
        "#@title HF dataset load and datamodule def\n",
        "import datasets\n",
        "from datasets import load_dataset\n",
        "from timm.data import resolve_data_config\n",
        "from timm.data.transforms_factory import create_transform\n",
        "\n",
        "\n",
        "# TODO add pinned memory and other loader optimizations to class as params\n",
        "# make a method to make the 3 loaders\n",
        "# TODO REVIEW TRAINING OPTIMIZATION NOTES\n",
        "# still unsure what of that Lightning does for you I dont think it does anything on dataset?\n",
        "class ImageWoofHGData(pl.LightningDataModule):\n",
        "  def __init__(self, batch_size: int = 32, model=None):\n",
        "    super().__init__()\n",
        "    self.save_hyperparameters(ignore=['model'])\n",
        "    self.batch_size = batch_size\n",
        "    self.model = model\n",
        "    self.datasets = []\n",
        "\n",
        "  # THIS PART WAS THE BIGGEST PAIN IN THE ASS I DO NOT LIKE HUGGING FACE DATASETS THE DATAMODULES ARE AWESOME BUT HUGGING FACE DATA SETS SUCK\n",
        "  # The data module guide said to do download in prepare but then\n",
        "  # technically supposed to do splits in setup?\n",
        "  def setup(self, stage: str):\n",
        "    # Download loading as splits\n",
        "    #image woof only has train and validation\n",
        "    datasets = load_dataset(\"frgfm/imagewoof\",\n",
        "                           \"full_size\",\n",
        "                           trust_remote_code=True,\n",
        "                           split=['train', 'validation[:50%]', 'validation[50%:]'])\n",
        "\n",
        "\n",
        "    # Create transform from model and assign to each dataset\n",
        "    # yes gross reaching into a global for model\n",
        "    vit_transform = create_transform(**resolve_data_config(model.pretrained_cfg, model=self.model))\n",
        "\n",
        "    def transforms(examples):\n",
        "      # is a list of all of that column\n",
        "      examples[\"pixels\"] = [vit_transform(image.convert(\"RGB\")) for image in examples[\"image\"]]\n",
        "      return examples\n",
        "\n",
        "    for ds in datasets:\n",
        "      dataset = ds.map(transforms, remove_columns=[\"image\"], batched=True)\n",
        "      dataset = dataset.with_format(\"torch\")\n",
        "      self.datasets.append(dataset)\n",
        "\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(self.datasets[0], batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(self.datasets[1], batch_size=self.batch_size)\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    return DataLoader(self.datasets[2], batch_size=self.batch_size)\n",
        "\n",
        "# apparently there is also a predict\n",
        "\n",
        "# datamodule = ImageWoofHGData()\n",
        "# datamodule.setup('fit')\n",
        "# train_loader = datamodule.train_dataloader()\n",
        "# for batch in train_loader:\n",
        "#   print(batch)\n",
        "#   break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2x5radmlDEq",
        "outputId": "f9b45b12-d33e-4448-b7cb-f9fec4a2b9d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compose(\n",
            "    Resize(size=248, interpolation=bicubic, max_size=None, antialias=True)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    MaybeToTensor()\n",
            "    Normalize(mean=tensor([0.5000, 0.5000, 0.5000]), std=tensor([0.5000, 0.5000, 0.5000]))\n",
            ")\n",
            "VisionTransformer(\n",
            "  (patch_embed): PatchEmbed(\n",
            "    (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
            "    (norm): Identity()\n",
            "  )\n",
            "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
            "  (patch_drop): Identity()\n",
            "  (norm_pre): Identity()\n",
            "  (blocks): Sequential(\n",
            "    (0): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (1): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (2): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (3): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (4): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (5): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (6): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (7): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (8): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (9): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (10): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (11): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (12): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (13): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (14): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (15): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (16): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (17): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (18): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (19): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (20): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (21): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (22): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (23): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "  )\n",
            "  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "  (fc_norm): Identity()\n",
            "  (head_drop): Dropout(p=0.0, inplace=False)\n",
            "  (head): Linear(in_features=1024, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "vit_transform = create_transform(**resolve_data_config(model.pretrained_cfg, model=model))\n",
        "print(vit_transform)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "qcHJfHF4ylV3",
        "outputId": "e387d18c-7749-440f-f247-5beaf8ec6924"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'ImageWoofHGData' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-106ccbc1f03d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#@title datamodule init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdatamodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageWoofHGData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ImageWoofHGData' is not defined"
          ]
        }
      ],
      "source": [
        "#@title datamodule init\n",
        "datamodule = ImageWoofHGData(model=model, batch_size=16)\n",
        "datamodule.setup('fit')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfFeJliSiWLl"
      },
      "outputs": [],
      "source": [
        "#@title Model def and init(including lighting module def and loop)\n",
        "import timm\n",
        "import torch.optim as optim\n",
        "\n",
        "class LightningVitL(pl.LightningModule):\n",
        "  def __init__(self, backbone, learning_rate=1e-4):\n",
        "    super().__init__()\n",
        "    # saves all args as hyper params that can then be accessed as self.ARG\n",
        "    self.save_hyperparameters(ignore=['backbone']) # already saved as part of checkpointing according to warning1\n",
        "    self.backbone = backbone\n",
        "    self.loss = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "  # this doesnt work anyways as I learned autologger overrides this\n",
        "\n",
        "  # I do it this way because for some reason the hijacked tensorboard autologger isnt logging params like this otherwise\n",
        "  # and it lets me include trainer params\n",
        "  def on_train_start(self):\n",
        "    # should really use decision code from here\n",
        "    #https://github.com/Lightning-AI/pytorch-lightning/blob/5dea36c5e2969aa8823213d6602e058db093ec57/src/lightning/pytorch/loggers/utilities.py#L59\n",
        "    # could also do this as a callback on the trainer itself\n",
        "    params = {**self.hparams,**self.trainer.datamodule.hparams} if self.trainer.datamodule else self.hparams\n",
        "    self.logger.log_hyperparams({**params, \"precision\": self.trainer.precision, \"accumulate_grad_batches\": self.trainer.accumulate_grad_batches, \"gradient_clip_val\": self.trainer.gradient_clip_val, \"gradient_clip_algorithm\": self.trainer.gradient_clip_algorithm, \"lr_scheduler_configs\": self.trainer.lr_scheduler_configs})\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.backbone(x)\n",
        "\n",
        "  def compute_metrics(self, batch, batch_idx):\n",
        "    x, y = batch['pixels'], batch['label']\n",
        "    scores = self.forward(x)\n",
        "    loss = self.loss(scores, y)\n",
        "\n",
        "    # calculate acc\n",
        "    labels_hat = torch.argmax(scores, dim=1)\n",
        "    accuracy = torch.sum(y == labels_hat).item() / (float(len(y)))\n",
        "    return loss, accuracy\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    loss, accuracy = self.compute_metrics(batch, batch_idx)\n",
        "    self.log_dict({'train_loss': loss, 'train_acc': accuracy})\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    loss, accuracy = self.compute_metrics(batch, batch_idx)\n",
        "    self.log_dict({'val_loss': loss, 'val_acc': accuracy})\n",
        "\n",
        "\n",
        "  def test_step(self, batch, batch_idx):\n",
        "    loss, accuracy = self.compute_metrics(batch, batch_idx)\n",
        "    self.log_dict({'test_loss': loss, 'test_acc': accuracy})\n",
        "\n",
        "  # MUST RETURN THE OPTIMIZER\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
        "    return optimizer\n",
        "    # lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
        "    # return {'optimizer': optimizer,\n",
        "    #         'lr_scheduler': {\n",
        "    #             'scheduler': lr_scheduler,\n",
        "    #             'interval': 'step',\n",
        "    #             'frequency': 1\n",
        "    #             }\n",
        "    #         }\n",
        "\n",
        "\n",
        "# print(model)\n",
        "# for name, param in model.named_parameters():\n",
        "#   if param.requires_grad:\n",
        "#     print(name)\n",
        "\n",
        "# print(is_model_frozen_anywhere(model))\n",
        "lightning_model = LightningVitL(backbone=model)\n",
        "# Compile the model\n",
        "# lightning_model = torch.compile(lightning_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTukvw3-idqv"
      },
      "outputs": [],
      "source": [
        "#@title Training\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.tuner import Tuner\n",
        "\n",
        "import mlflow.pytorch\n",
        "from mlflow import MlflowClient\n",
        "\n",
        "\n",
        "class log_hyperparameters(pl.Callback):\n",
        "    def on_train_start(self, trainer, pl_module):\n",
        "      print(\"logging hyperparameters\")\n",
        "      params = {**pl_module.hparams,**trainer.datamodule.hparams} if trainer.datamodule else pl_module.hparams\n",
        "      pl_module.logger.log_hyperparams({**params, \"precision\": pl_module.trainer.precision, \"accumulate_grad_batches\": trainer.accumulate_grad_batches, \"gradient_clip_val\": trainer.gradient_clip_val, \"gradient_clip_algorithm\": trainer.gradient_clip_algorithm, \"lr_scheduler_configs\": trainer.lr_scheduler_configs})\n",
        "\n",
        "class nvidia_smi(pl.Callback):\n",
        "    def __init__(self, n_steps):\n",
        "        self.n_steps = n_steps\n",
        "        self.current_step = 0\n",
        "\n",
        "    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n",
        "      self.current_step += 1\n",
        "      self.current_step %= self.n_steps\n",
        "      if self.current_step == 0:\n",
        "        # Your custom logic here\n",
        "        print(f\"Custom action at global step {self.global_step}\")\n",
        "\n",
        "\n",
        "# even this callback is still being overriden by the autologger\n",
        "trainer = Trainer(max_epochs=10, callbacks=[log_hyperparameters()])\n",
        "\n",
        "\n",
        "# Auto log all MLflow entities\n",
        "mlflow.pytorch.autolog(log_every_n_step=10, checkpoint_save_freq='epoch', checkpoint_save_best_only=False)\n",
        "# mlflow.pytorch.autolog(log_every_n_step=10)\n",
        "\n",
        "# Train the model.\n",
        "with mlflow.start_run() as run:\n",
        "  print(run.info)\n",
        "  trainer.fit(lightning_model, datamodule=datamodule)\n",
        "\n",
        "\n",
        "  # from pytorch_lightning.loggers import MLFlowLogger\n",
        "  # mlf_logger = MLFlowLogger(experiment_name=\"lightning_logs\", log_model='all', tracking_uri=userdata.get('MLFLOW_TRACKING_URI'))\n",
        "  # trainer = Trainer(enable_checkpointing='all', log_every_n_steps=1, logger=mlf_logger, max_epochs=10)\n",
        "\n",
        "  # trainer.fit(lightning_model, datamodule=datamodule)\n",
        "\n",
        "\n",
        "  # checkpoint_callback = pl.callbacks.ModelCheckpoint(every_n_train_steps=1)\n",
        "  # trainer = Trainer(log_every_n_steps=1, logger=mlf_logger, max_epochs=10, callbacks=[checkpoint_callback])\n",
        "\n",
        "  # trainer = Trainer(log_every_n_steps=10, max_epochs=10, callbacks=[checkpoint_callback])\n",
        "\n",
        "  # trainer = Trainer(log_every_n_steps=1,\n",
        "  #                   max_epochs=10,\n",
        "  #                   callbacks=[checkpoint_callback, nvidiasmi(10)])\n",
        "\n",
        "\n",
        "  # datamodule = ImageWoofHGData(model=model, batch_size=16)\n",
        "  # will crash after using all available ram\n",
        "  # tuner = Tuner(trainer)\n",
        "  # tuner.scale_batch_size(lightning_model, mode=\"binsearch\", datamodule=datamodule) # will override LIGHTNING MODULES HPARAM (so trainer doesnt need result)\n",
        "\n",
        "# at least I Know how to use these parts...\n",
        "  # profiler = pl.profiler.PyTorchProfiler(profile_memory=False)\n",
        "  # trainer.fit(lightning_model, datamodule=datamodule, profiler=profiler)\n",
        "\n",
        "  # trainer.fit(lightning_model, datamodule=datamodule)\n",
        "\n",
        "def print_auto_logged_info(r):\n",
        "    tags = {k: v for k, v in r.data.tags.items() if not k.startswith(\"mlflow.\")}\n",
        "    artifacts = [f.path for f in MlflowClient().list_artifacts(r.info.run_id, \"model\")]\n",
        "    print(f\"run_id: {r.info.run_id}\")\n",
        "    print(f\"artifacts: {artifacts}\")\n",
        "    print(f\"params: {r.data.params}\")\n",
        "    print(f\"metrics: {r.data.metrics}\")\n",
        "    print(f\"tags: {tags}\")\n",
        "\n",
        "print_auto_logged_info(mlflow.get_run(run_id=run.info.run_id))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "12a63937f13b48039d0949d5f24bdf78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_411ee8783f234898b1306a3d11739009",
            "placeholder": "​",
            "style": "IPY_MODEL_8d2f6fc0d13540efac5714f4e58bcfe1",
            "value": " 1.22G/1.22G [00:15&lt;00:00, 37.3MB/s]"
          }
        },
        "411ee8783f234898b1306a3d11739009": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "575b38b944174b0ea8ad75633d1de0f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "692c08edb4fb47daa928333a50452747": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ab2310968034466934cabc25cc9eb2f",
            "max": 1217334682,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76e78c7c7cd2474389110a11aea7dd5a",
            "value": 1217334682
          }
        },
        "76e78c7c7cd2474389110a11aea7dd5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ab2310968034466934cabc25cc9eb2f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d2f6fc0d13540efac5714f4e58bcfe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96c63041ebfd47118e747266da8f708d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a473a9f1f97d46edb4b03d59bc7ddcbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96c63041ebfd47118e747266da8f708d",
            "placeholder": "​",
            "style": "IPY_MODEL_f38b94eea8d14a5d9f572d3679fe9c22",
            "value": "model.safetensors: 100%"
          }
        },
        "bf965af15b4540049a0136112bc4d6a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a473a9f1f97d46edb4b03d59bc7ddcbc",
              "IPY_MODEL_692c08edb4fb47daa928333a50452747",
              "IPY_MODEL_12a63937f13b48039d0949d5f24bdf78"
            ],
            "layout": "IPY_MODEL_575b38b944174b0ea8ad75633d1de0f6"
          }
        },
        "f38b94eea8d14a5d9f572d3679fe9c22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
