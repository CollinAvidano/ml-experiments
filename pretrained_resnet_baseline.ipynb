{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMLM5R-M6DGx",
        "outputId": "4ec5174f-a78b-4ecb-f89e-9a90fd70455e"
      },
      "outputs": [],
      "source": [
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install optuna\n",
        "\n",
        "!pip install pytorch-lightning\n",
        "# fix for collab env\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yak7cra864c1",
        "outputId": "7bc52c4a-776f-43a0-bcd8-cea72f36b43c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/cifar/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 12382136.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /content/cifar/cifar-10-python.tar.gz to /content/cifar\n"
          ]
        }
      ],
      "source": [
        "# DATASET LOAD\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "from torch import utils\n",
        "import os\n",
        "\n",
        "trans = transforms.Compose([\n",
        "  transforms.Resize((128,128)),\n",
        "  transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# TODO should do if gpu check\n",
        "kwargs = { \"pin_memory\": True, \"num_workers\": os.cpu_count() }\n",
        "dataset_train = CIFAR10(root=\"/content/cifar\", download=True, transform=trans)\n",
        "dataset_test = CIFAR10(root=\"/content/cifar\", train=False, transform=trans)\n",
        "train_loader = utils.data.DataLoader(dataset_train, **kwargs)\n",
        "test_loader = utils.data.DataLoader(dataset_test, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4Bv4krz5-1t",
        "outputId": "4e64919d-86fd-4de0-d175-2404e5d15e39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ResNet-18 from `Deep Residual Learning for Image Recognition <https://arxiv.org/abs/1512.03385>`__.\n",
            "\n",
            "    Args:\n",
            "        weights (:class:`~torchvision.models.ResNet18_Weights`, optional): The\n",
            "            pretrained weights to use. See\n",
            "            :class:`~torchvision.models.ResNet18_Weights` below for\n",
            "            more details, and possible values. By default, no pre-trained\n",
            "            weights are used.\n",
            "        progress (bool, optional): If True, displays a progress bar of the\n",
            "            download to stderr. Default is True.\n",
            "        **kwargs: parameters passed to the ``torchvision.models.resnet.ResNet``\n",
            "            base class. Please refer to the `source code\n",
            "            <https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py>`_\n",
            "            for more details about this class.\n",
            "\n",
            "    .. autoclass:: torchvision.models.ResNet18_Weights\n",
            "        :members:\n",
            "    \n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 64, 64]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 64, 64]             128\n",
            "              ReLU-3           [-1, 64, 64, 64]               0\n",
            "         MaxPool2d-4           [-1, 64, 32, 32]               0\n",
            "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
            "              ReLU-7           [-1, 64, 32, 32]               0\n",
            "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
            "             ReLU-10           [-1, 64, 32, 32]               0\n",
            "       BasicBlock-11           [-1, 64, 32, 32]               0\n",
            "           Conv2d-12           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 32, 32]             128\n",
            "             ReLU-14           [-1, 64, 32, 32]               0\n",
            "           Conv2d-15           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 32, 32]             128\n",
            "             ReLU-17           [-1, 64, 32, 32]               0\n",
            "       BasicBlock-18           [-1, 64, 32, 32]               0\n",
            "           Conv2d-19          [-1, 128, 16, 16]          73,728\n",
            "      BatchNorm2d-20          [-1, 128, 16, 16]             256\n",
            "             ReLU-21          [-1, 128, 16, 16]               0\n",
            "           Conv2d-22          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 16, 16]             256\n",
            "           Conv2d-24          [-1, 128, 16, 16]           8,192\n",
            "      BatchNorm2d-25          [-1, 128, 16, 16]             256\n",
            "             ReLU-26          [-1, 128, 16, 16]               0\n",
            "       BasicBlock-27          [-1, 128, 16, 16]               0\n",
            "           Conv2d-28          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 16, 16]             256\n",
            "             ReLU-30          [-1, 128, 16, 16]               0\n",
            "           Conv2d-31          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-32          [-1, 128, 16, 16]             256\n",
            "             ReLU-33          [-1, 128, 16, 16]               0\n",
            "       BasicBlock-34          [-1, 128, 16, 16]               0\n",
            "           Conv2d-35            [-1, 256, 8, 8]         294,912\n",
            "      BatchNorm2d-36            [-1, 256, 8, 8]             512\n",
            "             ReLU-37            [-1, 256, 8, 8]               0\n",
            "           Conv2d-38            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-39            [-1, 256, 8, 8]             512\n",
            "           Conv2d-40            [-1, 256, 8, 8]          32,768\n",
            "      BatchNorm2d-41            [-1, 256, 8, 8]             512\n",
            "             ReLU-42            [-1, 256, 8, 8]               0\n",
            "       BasicBlock-43            [-1, 256, 8, 8]               0\n",
            "           Conv2d-44            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-45            [-1, 256, 8, 8]             512\n",
            "             ReLU-46            [-1, 256, 8, 8]               0\n",
            "           Conv2d-47            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-48            [-1, 256, 8, 8]             512\n",
            "             ReLU-49            [-1, 256, 8, 8]               0\n",
            "       BasicBlock-50            [-1, 256, 8, 8]               0\n",
            "           Conv2d-51            [-1, 512, 4, 4]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-53            [-1, 512, 4, 4]               0\n",
            "           Conv2d-54            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-56            [-1, 512, 4, 4]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-58            [-1, 512, 4, 4]               0\n",
            "       BasicBlock-59            [-1, 512, 4, 4]               0\n",
            "           Conv2d-60            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-62            [-1, 512, 4, 4]               0\n",
            "           Conv2d-63            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-65            [-1, 512, 4, 4]               0\n",
            "       BasicBlock-66            [-1, 512, 4, 4]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                 [-1, 1000]         513,000\n",
            "================================================================\n",
            "Total params: 11,689,512\n",
            "Trainable params: 11,689,512\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.19\n",
            "Forward/backward pass size (MB): 20.51\n",
            "Params size (MB): 44.59\n",
            "Estimated Total Size (MB): 65.29\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_main\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import optim, nn,  utils, Tensor\n",
        "from itertools import repeat\n",
        "from torchsummary import summary\n",
        "from torchvision import models\n",
        "\n",
        "print(torch.hub.help(\"pytorch/vision\", \"resnet18\"))\n",
        "\n",
        "# import pprint\n",
        "# pprint.pp(torch.hub.list(\"pytorch/vision\"))\n",
        "\n",
        "# print(\"\\n\".join(torch.hub.list(\"pytorch/vision\")))\n",
        "\n",
        "\n",
        "# pretrained via string\n",
        "# model = torch.hub.load(\"pytorch/vision\", \"resnet18\", weights=\"IMAGENET1K_V1\")\n",
        "\n",
        "# pretrained via torchhub enum\n",
        "weights = torch.hub.load(\"pytorch/vision\", \"get_weight\", weights=\"ResNet34_Weights.IMAGENET1K_V1\")\n",
        "# model_pre = torch.hub.load(\"pytorch/vision\", \"resnet34\", weights=weights)\n",
        "\n",
        "# untrained\n",
        "# model = torch.hub.load(\"pytorch/vision\", \"resnet34\")\n",
        "# model = torch.hub.load(\"pytorch/vision\", \"resnet18\")\n",
        "\n",
        "# pretrained via model method\n",
        "# model = models.resnet18(pretrained=True)\n",
        "\n",
        "# untrained via model method (False is defaule)\n",
        "# model = models.resnet18(pretrained=False)\n",
        "\n",
        "summary(model.cuda(), (3, 128, 128))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfN43ag17JmL"
      },
      "outputs": [],
      "source": [
        "### LIGHTNING\n",
        "from pytorch_lightning import Trainer\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "class LightningResNet(pl.LightningModule):\n",
        "  def __init__(self, backbone, learning_rate=0.1, batch_size=1024):\n",
        "    super().__init__()\n",
        "    # saves all args as hyper params that can then be accessed as self.ARG\n",
        "    self.save_hyperparameters()\n",
        "    self.backbone = backbone\n",
        "    self.loss = nn.CrossEntropyLoss()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.backbone(x)\n",
        "\n",
        "  # MUST RETURN THE LOSS\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    x, y = batch\n",
        "    scores = self.forward(x)\n",
        "    loss = self.loss(scores, y)\n",
        "\n",
        "    # Logging to TensorBoard (if installed) by default\n",
        "    self.log('train_loss', loss)\n",
        "    return loss\n",
        "\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    x, y = batch\n",
        "    scores = self.forward(x)\n",
        "    loss = self.loss(scores, y)\n",
        "\n",
        "    # calculate acc\n",
        "    labels_hat = torch.argmax(scores, dim=1)\n",
        "    val_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)\n",
        "\n",
        "    # log the outputs!\n",
        "    self.log_dict({'val_loss': loss, 'val_acc': val_acc})\n",
        "\n",
        "\n",
        "  def test_step(self, batch, batch_idx):\n",
        "    x, y = batch\n",
        "    scores = self.forward(x)\n",
        "    loss = self.loss(scores, y)\n",
        "\n",
        "    # JUST USE TORCH METRICS IN THE FUTURE\n",
        "    # calculate acc\n",
        "    labels_hat = torch.argmax(scores, dim=1)\n",
        "    test_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)\n",
        "\n",
        "    # log the outputs!\n",
        "    self.log_dict({'test_loss': loss, 'test_acc': test_acc})\n",
        "\n",
        "\n",
        "  # MUST RETURN THE OPTIMIZER\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = optim.Adam(self.parameters(), lr=self.hparams.learning_rate, weight_decay=0.0001 )\n",
        "    return optimizer\n",
        "\n",
        "  def train_dataloader(self): #\n",
        "    return utils.data.DataLoader(dataset_train, batch_size=self.hparams.batch_size)\n",
        "\n",
        "  def val_dataloader(self): #\n",
        "    return utils.data.DataLoader(dataset_test, batch_size=self.hparams.batch_size)\n",
        "\n",
        "  def test_dataloader(self): #\n",
        "    return utils.data.DataLoader(dataset_test, batch_size=self.hparams.batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "7WRu2lqW9k22",
        "outputId": "1358aed3-edb4-4dc8-9adc-e5d885f3bce2"
      },
      "outputs": [],
      "source": [
        "### TRAIN DEFAULT\n",
        "import torch\n",
        "from pytorch_lightning.loggers import tensorboard\n",
        "\n",
        "# may be default_root_dir\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "checkpoint_callback = ModelCheckpoint(dirpath=checkpoint_dir, save_top_k=3, monitor=\"val_loss\")\n",
        "# note as I learned if the logger has a default dir it will prefer that OVER DEFAULT ROOT DIR but manually setting dirpath fixes that\n",
        "# https://github.com/Lightning-AI/pytorch-lightning/blob/90d04b5b86f37994cdceccc6de32f0e93b1cc7f0/src/lightning/pytorch/callbacks/model_checkpoint.py#L623\n",
        "# trainer = Trainer(callbacks=[checkpoint_callback], log_every_n_steps=10, default_root_dir=checkpoint_dir)\n",
        "trainer = Trainer(callbacks=[checkpoint_callback], log_every_n_steps=10)\n",
        "\n",
        "# # automatically restores model, epoch, step, LR schedulers, etc...\n",
        "# trainer.fit(model, ckpt_path=\"some/path/to/my_checkpoint.ckpt\")\n",
        "trainer.fit(model) # loaders as part of module should seperate to datamodule at some point\n",
        "\n",
        "checkpoint_callback.best_model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWwSdtex8Wjb"
      },
      "outputs": [],
      "source": [
        "### OPTUNA\n",
        "import optuna\n",
        "from pytorch_lightning import Trainer\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "    # Suggest a learning rate\n",
        "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
        "\n",
        "    # Set model's learning rate at creation\n",
        "    model = LightningResNet(learning_rate = lr, batch_size = 2048)\n",
        "\n",
        "    # Assuming you have a DataLoader instance named `train_dataloader`\n",
        "    trainer = Trainer(max_epochs=10, limit_train_batches=100, limit_val_batches=10, limit_test_batches=100)\n",
        "    trainer.fit(model, train_loader)\n",
        "\n",
        "    global results\n",
        "    results = trainer.test(model, test_loader)\n",
        "    # Return the validation loss or any other metric you want to optimize\n",
        "    # dont know why this returns a list with a dict inside it...\n",
        "    return results[0][\"test_loss\"]\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "# Print the best trial\n",
        "print(study.best_trial.params)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Just testing graphing in netron vs torchviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIlBaRgTw1fq"
      },
      "outputs": [],
      "source": [
        "!pip install onnx\n",
        "!pip install onnxscript\n",
        "!pip install -q netron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JF-_Qdwky-Fv"
      },
      "outputs": [],
      "source": [
        "torch_input = torch.randn(1, 3, 32, 32)\n",
        "output_path = \"/content/restnet34.onnx\"\n",
        "torch.onnx.export(model, torch_input, output_path, input_names=[\"image\"], output_names=[\"output\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQAvh5m0pJSm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import netron\n",
        "import portpicker\n",
        "from google.colab import output\n",
        "\n",
        "# model should come from another block\n",
        "# output_path = \"/content/output.pth\"\n",
        "# torch.save(model.state_dict(), output_path)\n",
        "\n",
        "port = portpicker.pick_unused_port()\n",
        "\n",
        "# Read the model file and start the netron browser.\n",
        "with output.temporary():\n",
        "  netron.start(output_path, port, browse=True)\n",
        "\n",
        "output.serve_kernel_port_as_iframe(port, height='800')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
