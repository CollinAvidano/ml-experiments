{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LH5elgV2F1p6",
        "outputId": "497a0e71-3a58-4352-c16a-61f999301a24"
      },
      "outputs": [],
      "source": [
        "!pip install autogluon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDNNdc4RQM3J",
        "outputId": "9d9c4bbc-8a29-4915-ac8c-31549d91ae10"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/Western-OC2-Lab/Intrusion-Detection-System-Using-Machine-Learning/refs/heads/main/data/CICIDS2017_sample.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IGmXM1gql_H",
        "outputId": "cc4570fe-4a03-4044-de0b-3deead8efab4"
      },
      "outputs": [],
      "source": [
        "!unzip /content/MachineLearningCSV.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "WpEqhtaYaxIt",
        "outputId": "19500d4c-6730-4f28-c4a1-f1957d8d9f1f"
      },
      "outputs": [],
      "source": [
        "# https://auto.gluon.ai/stable/index.html\n",
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "\n",
        "data = '/content/MachineLearningCVE/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv'\n",
        "# data = 'https://raw.githubusercontent.com/Western-OC2-Lab/Intrusion-Detection-System-Using-Machine-Learning/refs/heads/main/data/CICIDS2017_sample.csv'\n",
        "\n",
        "data = TabularDataset(data)\n",
        "train_data = data.sample(frac=0.9, random_state=42)\n",
        "test_data = data.drop(train_data.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7Wnp04_M-vR",
        "outputId": "d514187a-a3cd-4cfe-d3d9-25f709e82683"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20250117_214103\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       11.15 GB / 12.67 GB (88.0%)\n",
            "Disk Space Avail:   75.64 GB / 107.72 GB (70.2%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20250117_214103\"\n",
            "Train Data Rows:    50995\n",
            "Train Data Columns: 77\n",
            "Label Column:       Label\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t7 unique label values:  ['PortScan', 'BENIGN', 'DoS', 'Bot', 'WebAttack', 'BruteForce', 'Infiltration']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 7\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11390.88 MB\n",
            "\tTrain Data (Original)  Memory Usage: 29.96 MB (0.3% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 10 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tUseless Original Features (Count: 8): ['Bwd PSH Flags', 'Bwd URG Flags', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 9): ['SYN Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Avg Fwd Segment Size', 'Fwd Header Length.1', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('float', []) : 1 | ['Avg Fwd Segment Size']\n",
            "\t\t('int', [])   : 8 | ['SYN Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Fwd Header Length.1', 'Subflow Fwd Packets', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 23 | ['Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', ...]\n",
            "\t\t('int', [])   : 37 | ['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets', 'Total Length of Bwd Packets', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 23 | ['Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', ...]\n",
            "\t\t('int', [])       : 30 | ['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets', 'Total Length of Bwd Packets', ...]\n",
            "\t\t('int', ['bool']) :  7 | ['Fwd PSH Flags', 'Fwd URG Flags', 'FIN Flag Count', 'RST Flag Count', 'PSH Flag Count', ...]\n",
            "\t4.5s = Fit runtime\n",
            "\t60 features in original data used to generate 60 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 20.96 MB (0.2% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 4.86s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.04902441415825081, Train Rows: 48495, Val Rows: 2500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 13 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\tWarning: Exception caused KNeighborsUnif to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/knn/knn_model.py\", line 103, in _fit\n",
            "    self.model = self._get_model_type()(**params).fit(X, y)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py\", line 238, in fit\n",
            "    return self._fit(X, y)\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_base.py\", line 475, in _fit\n",
            "    X, y = self._validate_data(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 650, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n",
            "    X = check_array(\n",
            "        ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: KNeighborsDist ...\n",
            "\tWarning: Exception caused KNeighborsDist to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/knn/knn_model.py\", line 103, in _fit\n",
            "    self.model = self._get_model_type()(**params).fit(X, y)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py\", line 238, in fit\n",
            "    return self._fit(X, y)\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_base.py\", line 475, in _fit\n",
            "    X, y = self._validate_data(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 650, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n",
            "    X = check_array(\n",
            "        ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "No improvement since epoch 0: early stopping\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "\t0.4\t = Validation score   (accuracy)\n",
            "\t47.24s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "\t0.998\t = Validation score   (accuracy)\n",
            "\t18.1s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.9984\t = Validation score   (accuracy)\n",
            "\t14.07s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\tWarning: Exception caused RandomForestGini to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 222, in _compute_missing_values_in_feature_mask\n",
            "    _assert_all_finite_element_wise(X, xp=np, allow_nan=True, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: RandomForestEntr ...\n",
            "\tWarning: Exception caused RandomForestEntr to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 222, in _compute_missing_values_in_feature_mask\n",
            "    _assert_all_finite_element_wise(X, xp=np, allow_nan=True, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: CatBoost ...\n",
            "\t0.9936\t = Validation score   (accuracy)\n",
            "\t55.82s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\tWarning: Exception caused ExtraTreesGini to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 214, in _compute_missing_values_in_feature_mask\n",
            "    assert_all_finite(X, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 213, in assert_all_finite\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\tWarning: Exception caused ExtraTreesEntr to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 214, in _compute_missing_values_in_feature_mask\n",
            "    assert_all_finite(X, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 213, in assert_all_finite\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: XGBoost ...\n",
            "\tWarning: Exception caused XGBoost to fail during training... Skipping this model.\n",
            "\t\t[21:43:31] /workspace/src/data/../common/../data/gradient_index.h:94: Check failed: valid: Input data contains `inf` or a value too large, while `missing` is not set to `inf`\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x22dcbc) [0x7d0770e2dcbc]\n",
            "  [bt] (1) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x52a356) [0x7d077112a356]\n",
            "  [bt] (2) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51b617) [0x7d077111b617]\n",
            "  [bt] (3) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51dbbc) [0x7d077111dbbc]\n",
            "  [bt] (4) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x4cd1ca) [0x7d07710cd1ca]\n",
            "  [bt] (5) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(XGQuantileDMatrixCreateFromCallback+0x18c) [0x7d0770d4556c]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7d089ac32e2e]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7d089ac2f493]\n",
            "  [bt] (8) /usr/lib/python3.11/lib-dynload/_ctypes.cpython-311-x86_64-linux-gnu.so(+0xa4d8) [0x7d089ac584d8]\n",
            "\n",
            "\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 194, in _fit\n",
            "    self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 1512, in fit\n",
            "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 596, in _wrap_evaluation_matrices\n",
            "    train_dmatrix = create_dmatrix(\n",
            "                    ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 1003, in _create_dmatrix\n",
            "    return QuantileDMatrix(\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 1573, in __init__\n",
            "    self._init(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 1634, in _init\n",
            "    _check_call(ret)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 284, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [21:43:31] /workspace/src/data/../common/../data/gradient_index.h:94: Check failed: valid: Input data contains `inf` or a value too large, while `missing` is not set to `inf`\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x22dcbc) [0x7d0770e2dcbc]\n",
            "  [bt] (1) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x52a356) [0x7d077112a356]\n",
            "  [bt] (2) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51b617) [0x7d077111b617]\n",
            "  [bt] (3) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51dbbc) [0x7d077111dbbc]\n",
            "  [bt] (4) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x4cd1ca) [0x7d07710cd1ca]\n",
            "  [bt] (5) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(XGQuantileDMatrixCreateFromCallback+0x18c) [0x7d0770d4556c]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7d089ac32e2e]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7d089ac2f493]\n",
            "  [bt] (8) /usr/lib/python3.11/lib-dynload/_ctypes.cpython-311-x86_64-linux-gnu.so(+0xa4d8) [0x7d089ac584d8]\n",
            "\n",
            "\n",
            "Fitting model: NeuralNetTorch ...\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/core/nanops.py:1256: RuntimeWarning: invalid value encountered in subtract\n",
            "  adjusted = values - mean\n",
            "\tWarning: Exception caused NeuralNetTorch to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float64').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
            "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
            "    dataset = self._process_train_data(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 744, in _process_train_data\n",
            "    df = self.processor.fit_transform(df)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\", line 976, in fit_transform\n",
            "    result = self._call_func_on_transformers(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\", line 885, in _call_func_on_transformers\n",
            "    return Parallel(n_jobs=self.n_jobs)(jobs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 74, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1918, in __call__\n",
            "    return output if self.return_generator else list(output)\n",
            "                                                ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
            "    res = func(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 136, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 533, in fit_transform\n",
            "    Xt = self._fit(X, y, routed_params)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 406, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/memory.py\", line 312, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1098, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 421, in fit\n",
            "    X = self._validate_input(X, in_fit=True)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 350, in _validate_input\n",
            "    raise ve\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 332, in _validate_input\n",
            "    X = self._validate_data(\n",
            "        ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 633, in _validate_data\n",
            "    out = check_array(X, input_name=\"X\", **check_params)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float64').\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.998\t = Validation score   (accuracy)\n",
            "\t14.85s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'LightGBM': 1.0}\n",
            "\t0.9984\t = Validation score   (accuracy)\n",
            "\t0.09s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 163.62s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 44963.1 rows/s (2500 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20250117_214103\")\n"
          ]
        }
      ],
      "source": [
        "predictor = TabularPredictor(label='Label').fit(train_data=train_data, num_gpus=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvQ53NX4PKlL",
        "outputId": "88f7210f-7b80-4619-d159-6ab9401b91be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 model  score_test  score_val eval_metric  pred_time_test  \\\n",
            "0             LightGBM    0.998235     0.9984    accuracy        0.113173   \n",
            "1  WeightedEnsemble_L2    0.998235     0.9984    accuracy        0.116729   \n",
            "2           LightGBMXT    0.996294     0.9980    accuracy        0.411423   \n",
            "3        LightGBMLarge    0.995588     0.9980    accuracy        0.105234   \n",
            "4             CatBoost    0.992234     0.9936    accuracy        0.048311   \n",
            "5      NeuralNetFastAI    0.412813     0.4000    accuracy        0.108102   \n",
            "\n",
            "   pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
            "0       0.054151  14.067505                 0.113173                0.054151   \n",
            "1       0.055601  14.159347                 0.003556                0.001450   \n",
            "2       0.174577  18.099866                 0.411423                0.174577   \n",
            "3       0.024274  14.854946                 0.105234                0.024274   \n",
            "4       0.015398  55.821312                 0.048311                0.015398   \n",
            "5       0.060932  47.242736                 0.108102                0.060932   \n",
            "\n",
            "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
            "0          14.067505            1       True          3  \n",
            "1           0.091842            2       True          6  \n",
            "2          18.099866            1       True          2  \n",
            "3          14.854946            1       True          5  \n",
            "4          55.821312            1       True          4  \n",
            "5          47.242736            1       True          1  \n",
            "5666\n",
            "5656\n",
            "{'accuracy': 0.9982350864807624, 'balanced_accuracy': 0.9973406215783848, 'mcc': 0.9974741448845872}\n"
          ]
        }
      ],
      "source": [
        "print(predictor.leaderboard(test_data))\n",
        "print(len(test_data))\n",
        "predictions = predictor.predict(test_data)\n",
        "print(len(test_data[predictions == test_data['Label']]))\n",
        "\n",
        "print(predictor.evaluate(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0hQ8EaSU8VU",
        "outputId": "359c1fb2-2ea9-4257-f54c-f8de06c2c3db"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20250118_022055\"\n",
            "Warning: `cache_data=False` will disable or limit advanced functionality after training such as feature importance calculations. It is recommended to set `cache_data=True` unless you explicitly wish to not have the data saved to disk.\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.61 GB / 12.67 GB (83.7%)\n",
            "Disk Space Avail:   75.24 GB / 107.72 GB (69.8%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20250118_022055\"\n",
            "Train Data Rows:    50995\n",
            "Train Data Columns: 77\n",
            "Label Column:       Label\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t7 unique label values:  ['BENIGN', 'DoS', 'PortScan', 'Bot', 'BruteForce', 'WebAttack', 'Infiltration']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 7\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    10841.17 MB\n",
            "\tTrain Data (Original)  Memory Usage: 29.96 MB (0.3% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 10 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tUseless Original Features (Count: 8): ['Bwd PSH Flags', 'Bwd URG Flags', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 11): ['SYN Flag Count', 'RST Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Header Length.1', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('float', []) : 2 | ['Avg Fwd Segment Size', 'Avg Bwd Segment Size']\n",
            "\t\t('int', [])   : 9 | ['SYN Flag Count', 'RST Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Fwd Header Length.1', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 22 | ['Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', ...]\n",
            "\t\t('int', [])   : 36 | ['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets', 'Total Length of Bwd Packets', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 22 | ['Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', ...]\n",
            "\t\t('int', [])       : 30 | ['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets', 'Total Length of Bwd Packets', ...]\n",
            "\t\t('int', ['bool']) :  6 | ['Fwd PSH Flags', 'Fwd URG Flags', 'FIN Flag Count', 'PSH Flag Count', 'ACK Flag Count', ...]\n",
            "\t3.1s = Fit runtime\n",
            "\t58 features in original data used to generate 58 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 20.52 MB (0.2% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 3.33s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.04902441415825081, Train Rows: 48495, Val Rows: 2500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 13 L1 models, fit_strategy=\"parallel\" ...\n",
            "Note: fit_strategy='parallel', but `num_cpus=2`. Running parallel mode with fewer than 12 CPUs is not recommended and has been disabled. You can override this by specifying `os.environ[\"AG_FORCE_PARALLEL\"] = \"True\"`. Falling back to fit_strategy='sequential' ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\tWarning: Exception caused KNeighborsUnif to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/knn/knn_model.py\", line 103, in _fit\n",
            "    self.model = self._get_model_type()(**params).fit(X, y)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py\", line 238, in fit\n",
            "    return self._fit(X, y)\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_base.py\", line 475, in _fit\n",
            "    X, y = self._validate_data(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 650, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n",
            "    X = check_array(\n",
            "        ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: KNeighborsDist ...\n",
            "\tWarning: Exception caused KNeighborsDist to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/knn/knn_model.py\", line 103, in _fit\n",
            "    self.model = self._get_model_type()(**params).fit(X, y)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py\", line 238, in fit\n",
            "    return self._fit(X, y)\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_base.py\", line 475, in _fit\n",
            "    X, y = self._validate_data(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 650, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n",
            "    X = check_array(\n",
            "        ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "No improvement since epoch 0: early stopping\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "\t0.4016\t = Validation score   (accuracy)\n",
            "\t47.31s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.9968\t = Validation score   (accuracy)\n",
            "\t23.28s\t = Training   runtime\n",
            "\t0.27s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.9984\t = Validation score   (accuracy)\n",
            "\t21.06s\t = Training   runtime\n",
            "\t0.23s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\tWarning: Exception caused RandomForestGini to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 222, in _compute_missing_values_in_feature_mask\n",
            "    _assert_all_finite_element_wise(X, xp=np, allow_nan=True, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: RandomForestEntr ...\n",
            "\tWarning: Exception caused RandomForestEntr to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 222, in _compute_missing_values_in_feature_mask\n",
            "    _assert_all_finite_element_wise(X, xp=np, allow_nan=True, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: CatBoost ...\n",
            "\t0.9976\t = Validation score   (accuracy)\n",
            "\t151.69s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\tWarning: Exception caused ExtraTreesGini to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 214, in _compute_missing_values_in_feature_mask\n",
            "    assert_all_finite(X, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 213, in assert_all_finite\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\tWarning: Exception caused ExtraTreesEntr to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 214, in _compute_missing_values_in_feature_mask\n",
            "    assert_all_finite(X, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 213, in assert_all_finite\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: XGBoost ...\n",
            "\tWarning: Exception caused XGBoost to fail during training... Skipping this model.\n",
            "\t\t[02:25:06] /workspace/src/data/../common/../data/gradient_index.h:94: Check failed: valid: Input data contains `inf` or a value too large, while `missing` is not set to `inf`\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x22dcbc) [0x7d0770e2dcbc]\n",
            "  [bt] (1) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x52a356) [0x7d077112a356]\n",
            "  [bt] (2) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51b617) [0x7d077111b617]\n",
            "  [bt] (3) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51dbbc) [0x7d077111dbbc]\n",
            "  [bt] (4) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x4cd1ca) [0x7d07710cd1ca]\n",
            "  [bt] (5) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(XGQuantileDMatrixCreateFromCallback+0x18c) [0x7d0770d4556c]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7d089ac32e2e]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7d089ac2f493]\n",
            "  [bt] (8) /usr/lib/python3.11/lib-dynload/_ctypes.cpython-311-x86_64-linux-gnu.so(+0xa4d8) [0x7d089ac584d8]\n",
            "\n",
            "\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 194, in _fit\n",
            "    self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 1512, in fit\n",
            "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 596, in _wrap_evaluation_matrices\n",
            "    train_dmatrix = create_dmatrix(\n",
            "                    ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 1003, in _create_dmatrix\n",
            "    return QuantileDMatrix(\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 1573, in __init__\n",
            "    self._init(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 1634, in _init\n",
            "    _check_call(ret)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 284, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [02:25:06] /workspace/src/data/../common/../data/gradient_index.h:94: Check failed: valid: Input data contains `inf` or a value too large, while `missing` is not set to `inf`\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x22dcbc) [0x7d0770e2dcbc]\n",
            "  [bt] (1) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x52a356) [0x7d077112a356]\n",
            "  [bt] (2) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51b617) [0x7d077111b617]\n",
            "  [bt] (3) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51dbbc) [0x7d077111dbbc]\n",
            "  [bt] (4) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x4cd1ca) [0x7d07710cd1ca]\n",
            "  [bt] (5) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(XGQuantileDMatrixCreateFromCallback+0x18c) [0x7d0770d4556c]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7d089ac32e2e]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7d089ac2f493]\n",
            "  [bt] (8) /usr/lib/python3.11/lib-dynload/_ctypes.cpython-311-x86_64-linux-gnu.so(+0xa4d8) [0x7d089ac584d8]\n",
            "\n",
            "\n",
            "Fitting model: NeuralNetTorch ...\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/core/nanops.py:1256: RuntimeWarning: invalid value encountered in subtract\n",
            "  adjusted = values - mean\n",
            "\tWarning: Exception caused NeuralNetTorch to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float64').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
            "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
            "    dataset = self._process_train_data(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 744, in _process_train_data\n",
            "    df = self.processor.fit_transform(df)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\", line 976, in fit_transform\n",
            "    result = self._call_func_on_transformers(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\", line 885, in _call_func_on_transformers\n",
            "    return Parallel(n_jobs=self.n_jobs)(jobs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 74, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1918, in __call__\n",
            "    return output if self.return_generator else list(output)\n",
            "                                                ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
            "    res = func(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 136, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 533, in fit_transform\n",
            "    Xt = self._fit(X, y, routed_params)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 406, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/memory.py\", line 312, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1098, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 421, in fit\n",
            "    X = self._validate_input(X, in_fit=True)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 350, in _validate_input\n",
            "    raise ve\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 332, in _validate_input\n",
            "    X = self._validate_data(\n",
            "        ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 633, in _validate_data\n",
            "    out = check_array(X, input_name=\"X\", **check_params)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float64').\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.9968\t = Validation score   (accuracy)\n",
            "\t24.4s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'LightGBM': 1.0}\n",
            "\t0.9984\t = Validation score   (accuracy)\n",
            "\t0.09s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 276.08s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 10889.9 rows/s (2500 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20250118_022055\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20250118_022532\"\n",
            "Warning: `cache_data=False` will disable or limit advanced functionality after training such as feature importance calculations. It is recommended to set `cache_data=True` unless you explicitly wish to not have the data saved to disk.\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.67 GB / 12.67 GB (84.2%)\n",
            "Disk Space Avail:   75.22 GB / 107.72 GB (69.8%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20250118_022532\"\n",
            "Train Data Rows:    50995\n",
            "Train Data Columns: 77\n",
            "Label Column:       Label\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t7 unique label values:  ['DoS', 'BENIGN', 'PortScan', 'WebAttack', 'BruteForce', 'Bot', 'Infiltration']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 7\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    10952.59 MB\n",
            "\tTrain Data (Original)  Memory Usage: 29.96 MB (0.3% of available memory)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9977056124249912\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 8 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tUseless Original Features (Count: 10): ['Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'CWE Flag Count', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 9): ['SYN Flag Count', 'ECE Flag Count', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Header Length.1', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('float', []) : 2 | ['Avg Fwd Segment Size', 'Avg Bwd Segment Size']\n",
            "\t\t('int', [])   : 7 | ['SYN Flag Count', 'ECE Flag Count', 'Fwd Header Length.1', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 22 | ['Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', ...]\n",
            "\t\t('int', [])   : 36 | ['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets', 'Total Length of Bwd Packets', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 22 | ['Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', ...]\n",
            "\t\t('int', [])       : 30 | ['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets', 'Total Length of Bwd Packets', ...]\n",
            "\t\t('int', ['bool']) :  6 | ['Fwd PSH Flags', 'FIN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', ...]\n",
            "\t3.0s = Fit runtime\n",
            "\t58 features in original data used to generate 58 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 20.52 MB (0.2% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 3.14s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.04902441415825081, Train Rows: 48495, Val Rows: 2500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 13 L1 models, fit_strategy=\"parallel\" ...\n",
            "Note: fit_strategy='parallel', but `num_cpus=2`. Running parallel mode with fewer than 12 CPUs is not recommended and has been disabled. You can override this by specifying `os.environ[\"AG_FORCE_PARALLEL\"] = \"True\"`. Falling back to fit_strategy='sequential' ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\tWarning: Exception caused KNeighborsUnif to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/knn/knn_model.py\", line 103, in _fit\n",
            "    self.model = self._get_model_type()(**params).fit(X, y)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py\", line 238, in fit\n",
            "    return self._fit(X, y)\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_base.py\", line 475, in _fit\n",
            "    X, y = self._validate_data(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 650, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n",
            "    X = check_array(\n",
            "        ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: KNeighborsDist ...\n",
            "\tWarning: Exception caused KNeighborsDist to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/knn/knn_model.py\", line 103, in _fit\n",
            "    self.model = self._get_model_type()(**params).fit(X, y)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py\", line 238, in fit\n",
            "    return self._fit(X, y)\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_base.py\", line 475, in _fit\n",
            "    X, y = self._validate_data(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 650, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n",
            "    X = check_array(\n",
            "        ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "No improvement since epoch 0: early stopping\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "\t0.4\t = Validation score   (accuracy)\n",
            "\t45.91s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.9948\t = Validation score   (accuracy)\n",
            "\t18.72s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.996\t = Validation score   (accuracy)\n",
            "\t16.97s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\tWarning: Exception caused RandomForestGini to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 222, in _compute_missing_values_in_feature_mask\n",
            "    _assert_all_finite_element_wise(X, xp=np, allow_nan=True, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: RandomForestEntr ...\n",
            "\tWarning: Exception caused RandomForestEntr to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 222, in _compute_missing_values_in_feature_mask\n",
            "    _assert_all_finite_element_wise(X, xp=np, allow_nan=True, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: CatBoost ...\n",
            "\t0.9948\t = Validation score   (accuracy)\n",
            "\t93.23s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\tWarning: Exception caused ExtraTreesGini to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 214, in _compute_missing_values_in_feature_mask\n",
            "    assert_all_finite(X, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 213, in assert_all_finite\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\tWarning: Exception caused ExtraTreesEntr to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 214, in _compute_missing_values_in_feature_mask\n",
            "    assert_all_finite(X, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 213, in assert_all_finite\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: XGBoost ...\n",
            "\tWarning: Exception caused XGBoost to fail during training... Skipping this model.\n",
            "\t\t[02:28:33] /workspace/src/data/../common/../data/gradient_index.h:94: Check failed: valid: Input data contains `inf` or a value too large, while `missing` is not set to `inf`\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x22dcbc) [0x7d0770e2dcbc]\n",
            "  [bt] (1) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x52a356) [0x7d077112a356]\n",
            "  [bt] (2) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51b617) [0x7d077111b617]\n",
            "  [bt] (3) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51dbbc) [0x7d077111dbbc]\n",
            "  [bt] (4) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x4cd1ca) [0x7d07710cd1ca]\n",
            "  [bt] (5) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(XGQuantileDMatrixCreateFromCallback+0x18c) [0x7d0770d4556c]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7d089ac32e2e]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7d089ac2f493]\n",
            "  [bt] (8) /usr/lib/python3.11/lib-dynload/_ctypes.cpython-311-x86_64-linux-gnu.so(+0xa4d8) [0x7d089ac584d8]\n",
            "\n",
            "\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 194, in _fit\n",
            "    self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 1512, in fit\n",
            "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 596, in _wrap_evaluation_matrices\n",
            "    train_dmatrix = create_dmatrix(\n",
            "                    ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 1003, in _create_dmatrix\n",
            "    return QuantileDMatrix(\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 1573, in __init__\n",
            "    self._init(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 1634, in _init\n",
            "    _check_call(ret)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 284, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [02:28:33] /workspace/src/data/../common/../data/gradient_index.h:94: Check failed: valid: Input data contains `inf` or a value too large, while `missing` is not set to `inf`\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x22dcbc) [0x7d0770e2dcbc]\n",
            "  [bt] (1) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x52a356) [0x7d077112a356]\n",
            "  [bt] (2) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51b617) [0x7d077111b617]\n",
            "  [bt] (3) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51dbbc) [0x7d077111dbbc]\n",
            "  [bt] (4) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x4cd1ca) [0x7d07710cd1ca]\n",
            "  [bt] (5) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(XGQuantileDMatrixCreateFromCallback+0x18c) [0x7d0770d4556c]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7d089ac32e2e]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7d089ac2f493]\n",
            "  [bt] (8) /usr/lib/python3.11/lib-dynload/_ctypes.cpython-311-x86_64-linux-gnu.so(+0xa4d8) [0x7d089ac584d8]\n",
            "\n",
            "\n",
            "Fitting model: NeuralNetTorch ...\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/core/nanops.py:1256: RuntimeWarning: invalid value encountered in subtract\n",
            "  adjusted = values - mean\n",
            "\tWarning: Exception caused NeuralNetTorch to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float64').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
            "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
            "    dataset = self._process_train_data(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 744, in _process_train_data\n",
            "    df = self.processor.fit_transform(df)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\", line 976, in fit_transform\n",
            "    result = self._call_func_on_transformers(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\", line 885, in _call_func_on_transformers\n",
            "    return Parallel(n_jobs=self.n_jobs)(jobs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 74, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1918, in __call__\n",
            "    return output if self.return_generator else list(output)\n",
            "                                                ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
            "    res = func(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 136, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 533, in fit_transform\n",
            "    Xt = self._fit(X, y, routed_params)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 406, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/memory.py\", line 312, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1098, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 421, in fit\n",
            "    X = self._validate_input(X, in_fit=True)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 350, in _validate_input\n",
            "    raise ve\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 332, in _validate_input\n",
            "    X = self._validate_data(\n",
            "        ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 633, in _validate_data\n",
            "    out = check_array(X, input_name=\"X\", **check_params)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float64').\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.9952\t = Validation score   (accuracy)\n",
            "\t16.14s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'LightGBM': 1.0}\n",
            "\t0.996\t = Validation score   (accuracy)\n",
            "\t0.1s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 197.87s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 49221.8 rows/s (2500 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20250118_022532\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20250118_022850\"\n",
            "Warning: `cache_data=False` will disable or limit advanced functionality after training such as feature importance calculations. It is recommended to set `cache_data=True` unless you explicitly wish to not have the data saved to disk.\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.71 GB / 12.67 GB (84.5%)\n",
            "Disk Space Avail:   75.21 GB / 107.72 GB (69.8%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20250118_022850\"\n",
            "Train Data Rows:    50995\n",
            "Train Data Columns: 77\n",
            "Label Column:       Label\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t7 unique label values:  ['DoS', 'BENIGN', 'PortScan', 'WebAttack', 'BruteForce', 'Bot', 'Infiltration']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 7\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9955877162019061\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\tAvailable Memory:                    10990.86 MB\n",
            "\tTrain Data (Original)  Memory Usage: 29.96 MB (0.3% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 8 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tUseless Original Features (Count: 10): ['Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'CWE Flag Count', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 9): ['SYN Flag Count', 'ECE Flag Count', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Header Length.1', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('float', []) : 2 | ['Avg Fwd Segment Size', 'Avg Bwd Segment Size']\n",
            "\t\t('int', [])   : 7 | ['SYN Flag Count', 'ECE Flag Count', 'Fwd Header Length.1', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 22 | ['Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', ...]\n",
            "\t\t('int', [])   : 36 | ['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets', 'Total Length of Bwd Packets', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 22 | ['Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', ...]\n",
            "\t\t('int', [])       : 30 | ['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets', 'Total Length of Bwd Packets', ...]\n",
            "\t\t('int', ['bool']) :  6 | ['Fwd PSH Flags', 'FIN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', ...]\n",
            "\t3.3s = Fit runtime\n",
            "\t58 features in original data used to generate 58 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 20.52 MB (0.2% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 3.46s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.04902441415825081, Train Rows: 48495, Val Rows: 2500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 13 L1 models, fit_strategy=\"parallel\" ...\n",
            "Note: fit_strategy='parallel', but `num_cpus=2`. Running parallel mode with fewer than 12 CPUs is not recommended and has been disabled. You can override this by specifying `os.environ[\"AG_FORCE_PARALLEL\"] = \"True\"`. Falling back to fit_strategy='sequential' ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\tWarning: Exception caused KNeighborsUnif to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/knn/knn_model.py\", line 103, in _fit\n",
            "    self.model = self._get_model_type()(**params).fit(X, y)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py\", line 238, in fit\n",
            "    return self._fit(X, y)\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_base.py\", line 475, in _fit\n",
            "    X, y = self._validate_data(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 650, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n",
            "    X = check_array(\n",
            "        ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: KNeighborsDist ...\n",
            "\tWarning: Exception caused KNeighborsDist to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/knn/knn_model.py\", line 103, in _fit\n",
            "    self.model = self._get_model_type()(**params).fit(X, y)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py\", line 238, in fit\n",
            "    return self._fit(X, y)\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_base.py\", line 475, in _fit\n",
            "    X, y = self._validate_data(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 650, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n",
            "    X = check_array(\n",
            "        ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "No improvement since epoch 0: early stopping\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "\t0.4\t = Validation score   (accuracy)\n",
            "\t45.88s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.9948\t = Validation score   (accuracy)\n",
            "\t16.31s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.996\t = Validation score   (accuracy)\n",
            "\t13.68s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\tWarning: Exception caused RandomForestGini to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 222, in _compute_missing_values_in_feature_mask\n",
            "    _assert_all_finite_element_wise(X, xp=np, allow_nan=True, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: RandomForestEntr ...\n",
            "\tWarning: Exception caused RandomForestEntr to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 222, in _compute_missing_values_in_feature_mask\n",
            "    _assert_all_finite_element_wise(X, xp=np, allow_nan=True, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: CatBoost ...\n",
            "\t0.9948\t = Validation score   (accuracy)\n",
            "\t91.82s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\tWarning: Exception caused ExtraTreesGini to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 214, in _compute_missing_values_in_feature_mask\n",
            "    assert_all_finite(X, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 213, in assert_all_finite\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\tWarning: Exception caused ExtraTreesEntr to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 214, in _compute_missing_values_in_feature_mask\n",
            "    assert_all_finite(X, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 213, in assert_all_finite\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: XGBoost ...\n",
            "\tWarning: Exception caused XGBoost to fail during training... Skipping this model.\n",
            "\t\t[02:31:45] /workspace/src/data/../common/../data/gradient_index.h:94: Check failed: valid: Input data contains `inf` or a value too large, while `missing` is not set to `inf`\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x22dcbc) [0x7d0770e2dcbc]\n",
            "  [bt] (1) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x52a356) [0x7d077112a356]\n",
            "  [bt] (2) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51b617) [0x7d077111b617]\n",
            "  [bt] (3) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51dbbc) [0x7d077111dbbc]\n",
            "  [bt] (4) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x4cd1ca) [0x7d07710cd1ca]\n",
            "  [bt] (5) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(XGQuantileDMatrixCreateFromCallback+0x18c) [0x7d0770d4556c]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7d089ac32e2e]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7d089ac2f493]\n",
            "  [bt] (8) /usr/lib/python3.11/lib-dynload/_ctypes.cpython-311-x86_64-linux-gnu.so(+0xa4d8) [0x7d089ac584d8]\n",
            "\n",
            "\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 194, in _fit\n",
            "    self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 1512, in fit\n",
            "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 596, in _wrap_evaluation_matrices\n",
            "    train_dmatrix = create_dmatrix(\n",
            "                    ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 1003, in _create_dmatrix\n",
            "    return QuantileDMatrix(\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 1573, in __init__\n",
            "    self._init(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 1634, in _init\n",
            "    _check_call(ret)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 284, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [02:31:45] /workspace/src/data/../common/../data/gradient_index.h:94: Check failed: valid: Input data contains `inf` or a value too large, while `missing` is not set to `inf`\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x22dcbc) [0x7d0770e2dcbc]\n",
            "  [bt] (1) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x52a356) [0x7d077112a356]\n",
            "  [bt] (2) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51b617) [0x7d077111b617]\n",
            "  [bt] (3) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51dbbc) [0x7d077111dbbc]\n",
            "  [bt] (4) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x4cd1ca) [0x7d07710cd1ca]\n",
            "  [bt] (5) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(XGQuantileDMatrixCreateFromCallback+0x18c) [0x7d0770d4556c]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7d089ac32e2e]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7d089ac2f493]\n",
            "  [bt] (8) /usr/lib/python3.11/lib-dynload/_ctypes.cpython-311-x86_64-linux-gnu.so(+0xa4d8) [0x7d089ac584d8]\n",
            "\n",
            "\n",
            "Fitting model: NeuralNetTorch ...\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/core/nanops.py:1256: RuntimeWarning: invalid value encountered in subtract\n",
            "  adjusted = values - mean\n",
            "\tWarning: Exception caused NeuralNetTorch to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float64').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
            "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
            "    dataset = self._process_train_data(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 744, in _process_train_data\n",
            "    df = self.processor.fit_transform(df)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\", line 976, in fit_transform\n",
            "    result = self._call_func_on_transformers(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\", line 885, in _call_func_on_transformers\n",
            "    return Parallel(n_jobs=self.n_jobs)(jobs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 74, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1918, in __call__\n",
            "    return output if self.return_generator else list(output)\n",
            "                                                ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
            "    res = func(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 136, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 533, in fit_transform\n",
            "    Xt = self._fit(X, y, routed_params)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 406, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/memory.py\", line 312, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1098, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 421, in fit\n",
            "    X = self._validate_input(X, in_fit=True)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 350, in _validate_input\n",
            "    raise ve\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 332, in _validate_input\n",
            "    X = self._validate_data(\n",
            "        ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 633, in _validate_data\n",
            "    out = check_array(X, input_name=\"X\", **check_params)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float64').\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.9952\t = Validation score   (accuracy)\n",
            "\t17.73s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'LightGBM': 1.0}\n",
            "\t0.996\t = Validation score   (accuracy)\n",
            "\t0.09s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 192.99s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 40389.8 rows/s (2500 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20250118_022850\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20250118_023203\"\n",
            "Warning: `cache_data=False` will disable or limit advanced functionality after training such as feature importance calculations. It is recommended to set `cache_data=True` unless you explicitly wish to not have the data saved to disk.\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.73 GB / 12.67 GB (84.6%)\n",
            "Disk Space Avail:   75.20 GB / 107.72 GB (69.8%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20250118_023203\"\n",
            "Train Data Rows:    50995\n",
            "Train Data Columns: 77\n",
            "Label Column:       Label\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t7 unique label values:  ['DoS', 'BENIGN', 'PortScan', 'WebAttack', 'BruteForce', 'Bot', 'Infiltration']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 7\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9955877162019061\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\tAvailable Memory:                    10993.81 MB\n",
            "\tTrain Data (Original)  Memory Usage: 29.96 MB (0.3% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 8 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tUseless Original Features (Count: 10): ['Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'CWE Flag Count', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 9): ['SYN Flag Count', 'ECE Flag Count', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Header Length.1', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('float', []) : 2 | ['Avg Fwd Segment Size', 'Avg Bwd Segment Size']\n",
            "\t\t('int', [])   : 7 | ['SYN Flag Count', 'ECE Flag Count', 'Fwd Header Length.1', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 22 | ['Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', ...]\n",
            "\t\t('int', [])   : 36 | ['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets', 'Total Length of Bwd Packets', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 22 | ['Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', ...]\n",
            "\t\t('int', [])       : 30 | ['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets', 'Total Length of Bwd Packets', ...]\n",
            "\t\t('int', ['bool']) :  6 | ['Fwd PSH Flags', 'FIN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', ...]\n",
            "\t4.0s = Fit runtime\n",
            "\t58 features in original data used to generate 58 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 20.52 MB (0.2% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 4.19s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.04902441415825081, Train Rows: 48495, Val Rows: 2500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 13 L1 models, fit_strategy=\"parallel\" ...\n",
            "Note: fit_strategy='parallel', but `num_cpus=2`. Running parallel mode with fewer than 12 CPUs is not recommended and has been disabled. You can override this by specifying `os.environ[\"AG_FORCE_PARALLEL\"] = \"True\"`. Falling back to fit_strategy='sequential' ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\tWarning: Exception caused KNeighborsUnif to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/knn/knn_model.py\", line 103, in _fit\n",
            "    self.model = self._get_model_type()(**params).fit(X, y)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py\", line 238, in fit\n",
            "    return self._fit(X, y)\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_base.py\", line 475, in _fit\n",
            "    X, y = self._validate_data(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 650, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n",
            "    X = check_array(\n",
            "        ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: KNeighborsDist ...\n",
            "\tWarning: Exception caused KNeighborsDist to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/knn/knn_model.py\", line 103, in _fit\n",
            "    self.model = self._get_model_type()(**params).fit(X, y)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py\", line 238, in fit\n",
            "    return self._fit(X, y)\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_base.py\", line 475, in _fit\n",
            "    X, y = self._validate_data(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 650, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n",
            "    X = check_array(\n",
            "        ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "No improvement since epoch 0: early stopping\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "\t0.4\t = Validation score   (accuracy)\n",
            "\t46.45s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.9948\t = Validation score   (accuracy)\n",
            "\t16.24s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.996\t = Validation score   (accuracy)\n",
            "\t13.08s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\tWarning: Exception caused RandomForestGini to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 222, in _compute_missing_values_in_feature_mask\n",
            "    _assert_all_finite_element_wise(X, xp=np, allow_nan=True, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: RandomForestEntr ...\n",
            "\tWarning: Exception caused RandomForestEntr to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 222, in _compute_missing_values_in_feature_mask\n",
            "    _assert_all_finite_element_wise(X, xp=np, allow_nan=True, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: CatBoost ...\n",
            "\t0.9948\t = Validation score   (accuracy)\n",
            "\t92.06s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\tWarning: Exception caused ExtraTreesGini to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 214, in _compute_missing_values_in_feature_mask\n",
            "    assert_all_finite(X, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 213, in assert_all_finite\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\tWarning: Exception caused ExtraTreesEntr to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 214, in _compute_missing_values_in_feature_mask\n",
            "    assert_all_finite(X, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 213, in assert_all_finite\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: XGBoost ...\n",
            "\tWarning: Exception caused XGBoost to fail during training... Skipping this model.\n",
            "\t\t[02:34:58] /workspace/src/data/../common/../data/gradient_index.h:94: Check failed: valid: Input data contains `inf` or a value too large, while `missing` is not set to `inf`\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x22dcbc) [0x7d0770e2dcbc]\n",
            "  [bt] (1) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x52a356) [0x7d077112a356]\n",
            "  [bt] (2) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51b617) [0x7d077111b617]\n",
            "  [bt] (3) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51dbbc) [0x7d077111dbbc]\n",
            "  [bt] (4) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x4cd1ca) [0x7d07710cd1ca]\n",
            "  [bt] (5) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(XGQuantileDMatrixCreateFromCallback+0x18c) [0x7d0770d4556c]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7d089ac32e2e]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7d089ac2f493]\n",
            "  [bt] (8) /usr/lib/python3.11/lib-dynload/_ctypes.cpython-311-x86_64-linux-gnu.so(+0xa4d8) [0x7d089ac584d8]\n",
            "\n",
            "\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 194, in _fit\n",
            "    self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 1512, in fit\n",
            "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 596, in _wrap_evaluation_matrices\n",
            "    train_dmatrix = create_dmatrix(\n",
            "                    ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 1003, in _create_dmatrix\n",
            "    return QuantileDMatrix(\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 1573, in __init__\n",
            "    self._init(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 1634, in _init\n",
            "    _check_call(ret)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 284, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [02:34:58] /workspace/src/data/../common/../data/gradient_index.h:94: Check failed: valid: Input data contains `inf` or a value too large, while `missing` is not set to `inf`\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x22dcbc) [0x7d0770e2dcbc]\n",
            "  [bt] (1) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x52a356) [0x7d077112a356]\n",
            "  [bt] (2) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51b617) [0x7d077111b617]\n",
            "  [bt] (3) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51dbbc) [0x7d077111dbbc]\n",
            "  [bt] (4) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x4cd1ca) [0x7d07710cd1ca]\n",
            "  [bt] (5) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(XGQuantileDMatrixCreateFromCallback+0x18c) [0x7d0770d4556c]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7d089ac32e2e]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7d089ac2f493]\n",
            "  [bt] (8) /usr/lib/python3.11/lib-dynload/_ctypes.cpython-311-x86_64-linux-gnu.so(+0xa4d8) [0x7d089ac584d8]\n",
            "\n",
            "\n",
            "Fitting model: NeuralNetTorch ...\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/core/nanops.py:1256: RuntimeWarning: invalid value encountered in subtract\n",
            "  adjusted = values - mean\n",
            "\tWarning: Exception caused NeuralNetTorch to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float64').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
            "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
            "    dataset = self._process_train_data(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 744, in _process_train_data\n",
            "    df = self.processor.fit_transform(df)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\", line 976, in fit_transform\n",
            "    result = self._call_func_on_transformers(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\", line 885, in _call_func_on_transformers\n",
            "    return Parallel(n_jobs=self.n_jobs)(jobs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 74, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1918, in __call__\n",
            "    return output if self.return_generator else list(output)\n",
            "                                                ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
            "    res = func(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 136, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 533, in fit_transform\n",
            "    Xt = self._fit(X, y, routed_params)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 406, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/memory.py\", line 312, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1098, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 421, in fit\n",
            "    X = self._validate_input(X, in_fit=True)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 350, in _validate_input\n",
            "    raise ve\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 332, in _validate_input\n",
            "    X = self._validate_data(\n",
            "        ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 633, in _validate_data\n",
            "    out = check_array(X, input_name=\"X\", **check_params)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float64').\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.9952\t = Validation score   (accuracy)\n",
            "\t16.15s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'LightGBM': 1.0}\n",
            "\t0.996\t = Validation score   (accuracy)\n",
            "\t0.1s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 191.86s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 47467.1 rows/s (2500 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20250118_023203\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20250118_023516\"\n",
            "Warning: `cache_data=False` will disable or limit advanced functionality after training such as feature importance calculations. It is recommended to set `cache_data=True` unless you explicitly wish to not have the data saved to disk.\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.71 GB / 12.67 GB (84.5%)\n",
            "Disk Space Avail:   75.20 GB / 107.72 GB (69.8%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20250118_023516\"\n",
            "Train Data Rows:    50995\n",
            "Train Data Columns: 77\n",
            "Label Column:       Label\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t7 unique label values:  ['DoS', 'BENIGN', 'PortScan', 'WebAttack', 'BruteForce', 'Bot', 'Infiltration']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 7\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9955877162019061\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\tAvailable Memory:                    10984.29 MB\n",
            "\tTrain Data (Original)  Memory Usage: 29.96 MB (0.3% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 8 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tUseless Original Features (Count: 10): ['Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'CWE Flag Count', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 9): ['SYN Flag Count', 'ECE Flag Count', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Header Length.1', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('float', []) : 2 | ['Avg Fwd Segment Size', 'Avg Bwd Segment Size']\n",
            "\t\t('int', [])   : 7 | ['SYN Flag Count', 'ECE Flag Count', 'Fwd Header Length.1', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 22 | ['Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', ...]\n",
            "\t\t('int', [])   : 36 | ['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets', 'Total Length of Bwd Packets', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 22 | ['Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', ...]\n",
            "\t\t('int', [])       : 30 | ['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets', 'Total Length of Bwd Packets', ...]\n",
            "\t\t('int', ['bool']) :  6 | ['Fwd PSH Flags', 'FIN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', ...]\n",
            "\t4.1s = Fit runtime\n",
            "\t58 features in original data used to generate 58 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 20.52 MB (0.2% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 4.29s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.04902441415825081, Train Rows: 48495, Val Rows: 2500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 13 L1 models, fit_strategy=\"parallel\" ...\n",
            "Note: fit_strategy='parallel', but `num_cpus=2`. Running parallel mode with fewer than 12 CPUs is not recommended and has been disabled. You can override this by specifying `os.environ[\"AG_FORCE_PARALLEL\"] = \"True\"`. Falling back to fit_strategy='sequential' ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\tWarning: Exception caused KNeighborsUnif to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/knn/knn_model.py\", line 103, in _fit\n",
            "    self.model = self._get_model_type()(**params).fit(X, y)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py\", line 238, in fit\n",
            "    return self._fit(X, y)\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_base.py\", line 475, in _fit\n",
            "    X, y = self._validate_data(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 650, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n",
            "    X = check_array(\n",
            "        ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: KNeighborsDist ...\n",
            "\tWarning: Exception caused KNeighborsDist to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/knn/knn_model.py\", line 103, in _fit\n",
            "    self.model = self._get_model_type()(**params).fit(X, y)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py\", line 238, in fit\n",
            "    return self._fit(X, y)\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_base.py\", line 475, in _fit\n",
            "    X, y = self._validate_data(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 650, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n",
            "    X = check_array(\n",
            "        ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "No improvement since epoch 0: early stopping\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "\t0.4\t = Validation score   (accuracy)\n",
            "\t45.12s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.9948\t = Validation score   (accuracy)\n",
            "\t16.05s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.996\t = Validation score   (accuracy)\n",
            "\t12.98s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\tWarning: Exception caused RandomForestGini to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 222, in _compute_missing_values_in_feature_mask\n",
            "    _assert_all_finite_element_wise(X, xp=np, allow_nan=True, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: RandomForestEntr ...\n",
            "\tWarning: Exception caused RandomForestEntr to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 222, in _compute_missing_values_in_feature_mask\n",
            "    _assert_all_finite_element_wise(X, xp=np, allow_nan=True, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: CatBoost ...\n",
            "\t0.9948\t = Validation score   (accuracy)\n",
            "\t92.4s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\tWarning: Exception caused ExtraTreesGini to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 214, in _compute_missing_values_in_feature_mask\n",
            "    assert_all_finite(X, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 213, in assert_all_finite\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\tWarning: Exception caused ExtraTreesEntr to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 214, in _compute_missing_values_in_feature_mask\n",
            "    assert_all_finite(X, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 213, in assert_all_finite\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: XGBoost ...\n",
            "\tWarning: Exception caused XGBoost to fail during training... Skipping this model.\n",
            "\t\t[02:38:09] /workspace/src/data/../common/../data/gradient_index.h:94: Check failed: valid: Input data contains `inf` or a value too large, while `missing` is not set to `inf`\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x22dcbc) [0x7d0770e2dcbc]\n",
            "  [bt] (1) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x52a356) [0x7d077112a356]\n",
            "  [bt] (2) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51b617) [0x7d077111b617]\n",
            "  [bt] (3) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51dbbc) [0x7d077111dbbc]\n",
            "  [bt] (4) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x4cd1ca) [0x7d07710cd1ca]\n",
            "  [bt] (5) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(XGQuantileDMatrixCreateFromCallback+0x18c) [0x7d0770d4556c]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7d089ac32e2e]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7d089ac2f493]\n",
            "  [bt] (8) /usr/lib/python3.11/lib-dynload/_ctypes.cpython-311-x86_64-linux-gnu.so(+0xa4d8) [0x7d089ac584d8]\n",
            "\n",
            "\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 194, in _fit\n",
            "    self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 1512, in fit\n",
            "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 596, in _wrap_evaluation_matrices\n",
            "    train_dmatrix = create_dmatrix(\n",
            "                    ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 1003, in _create_dmatrix\n",
            "    return QuantileDMatrix(\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 1573, in __init__\n",
            "    self._init(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 1634, in _init\n",
            "    _check_call(ret)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 284, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [02:38:09] /workspace/src/data/../common/../data/gradient_index.h:94: Check failed: valid: Input data contains `inf` or a value too large, while `missing` is not set to `inf`\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x22dcbc) [0x7d0770e2dcbc]\n",
            "  [bt] (1) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x52a356) [0x7d077112a356]\n",
            "  [bt] (2) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51b617) [0x7d077111b617]\n",
            "  [bt] (3) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51dbbc) [0x7d077111dbbc]\n",
            "  [bt] (4) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x4cd1ca) [0x7d07710cd1ca]\n",
            "  [bt] (5) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(XGQuantileDMatrixCreateFromCallback+0x18c) [0x7d0770d4556c]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7d089ac32e2e]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7d089ac2f493]\n",
            "  [bt] (8) /usr/lib/python3.11/lib-dynload/_ctypes.cpython-311-x86_64-linux-gnu.so(+0xa4d8) [0x7d089ac584d8]\n",
            "\n",
            "\n",
            "Fitting model: NeuralNetTorch ...\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/core/nanops.py:1256: RuntimeWarning: invalid value encountered in subtract\n",
            "  adjusted = values - mean\n",
            "\tWarning: Exception caused NeuralNetTorch to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float64').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
            "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
            "    dataset = self._process_train_data(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 744, in _process_train_data\n",
            "    df = self.processor.fit_transform(df)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\", line 976, in fit_transform\n",
            "    result = self._call_func_on_transformers(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\", line 885, in _call_func_on_transformers\n",
            "    return Parallel(n_jobs=self.n_jobs)(jobs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 74, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1918, in __call__\n",
            "    return output if self.return_generator else list(output)\n",
            "                                                ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
            "    res = func(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 136, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 533, in fit_transform\n",
            "    Xt = self._fit(X, y, routed_params)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 406, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/memory.py\", line 312, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1098, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 421, in fit\n",
            "    X = self._validate_input(X, in_fit=True)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 350, in _validate_input\n",
            "    raise ve\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 332, in _validate_input\n",
            "    X = self._validate_data(\n",
            "        ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 633, in _validate_data\n",
            "    out = check_array(X, input_name=\"X\", **check_params)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float64').\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.9952\t = Validation score   (accuracy)\n",
            "\t16.08s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'LightGBM': 1.0}\n",
            "\t0.996\t = Validation score   (accuracy)\n",
            "\t0.1s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 190.69s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 49504.6 rows/s (2500 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20250118_023516\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20250118_023826\"\n",
            "Warning: `cache_data=False` will disable or limit advanced functionality after training such as feature importance calculations. It is recommended to set `cache_data=True` unless you explicitly wish to not have the data saved to disk.\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.71 GB / 12.67 GB (84.5%)\n",
            "Disk Space Avail:   75.19 GB / 107.72 GB (69.8%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20250118_023826\"\n",
            "Train Data Rows:    50995\n",
            "Train Data Columns: 77\n",
            "Label Column:       Label\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t7 unique label values:  ['DoS', 'BENIGN', 'PortScan', 'WebAttack', 'BruteForce', 'Bot', 'Infiltration']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9955877162019061\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Data Class Count: 7\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    10990.86 MB\n",
            "\tTrain Data (Original)  Memory Usage: 29.96 MB (0.3% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 8 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tUseless Original Features (Count: 10): ['Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'CWE Flag Count', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 9): ['SYN Flag Count', 'ECE Flag Count', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Header Length.1', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('float', []) : 2 | ['Avg Fwd Segment Size', 'Avg Bwd Segment Size']\n",
            "\t\t('int', [])   : 7 | ['SYN Flag Count', 'ECE Flag Count', 'Fwd Header Length.1', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 22 | ['Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', ...]\n",
            "\t\t('int', [])   : 36 | ['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets', 'Total Length of Bwd Packets', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 22 | ['Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', ...]\n",
            "\t\t('int', [])       : 30 | ['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets', 'Total Length of Bwd Packets', ...]\n",
            "\t\t('int', ['bool']) :  6 | ['Fwd PSH Flags', 'FIN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', ...]\n",
            "\t4.0s = Fit runtime\n",
            "\t58 features in original data used to generate 58 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 20.52 MB (0.2% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 4.23s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.04902441415825081, Train Rows: 48495, Val Rows: 2500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 13 L1 models, fit_strategy=\"parallel\" ...\n",
            "Note: fit_strategy='parallel', but `num_cpus=2`. Running parallel mode with fewer than 12 CPUs is not recommended and has been disabled. You can override this by specifying `os.environ[\"AG_FORCE_PARALLEL\"] = \"True\"`. Falling back to fit_strategy='sequential' ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\tWarning: Exception caused KNeighborsUnif to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/knn/knn_model.py\", line 103, in _fit\n",
            "    self.model = self._get_model_type()(**params).fit(X, y)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py\", line 238, in fit\n",
            "    return self._fit(X, y)\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_base.py\", line 475, in _fit\n",
            "    X, y = self._validate_data(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 650, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n",
            "    X = check_array(\n",
            "        ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: KNeighborsDist ...\n",
            "\tWarning: Exception caused KNeighborsDist to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/knn/knn_model.py\", line 103, in _fit\n",
            "    self.model = self._get_model_type()(**params).fit(X, y)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py\", line 238, in fit\n",
            "    return self._fit(X, y)\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_base.py\", line 475, in _fit\n",
            "    X, y = self._validate_data(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 650, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n",
            "    X = check_array(\n",
            "        ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "No improvement since epoch 0: early stopping\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "\t0.4\t = Validation score   (accuracy)\n",
            "\t45.94s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.9948\t = Validation score   (accuracy)\n",
            "\t16.69s\t = Training   runtime\n",
            "\t0.18s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.996\t = Validation score   (accuracy)\n",
            "\t12.93s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\tWarning: Exception caused RandomForestGini to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 222, in _compute_missing_values_in_feature_mask\n",
            "    _assert_all_finite_element_wise(X, xp=np, allow_nan=True, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: RandomForestEntr ...\n",
            "\tWarning: Exception caused RandomForestEntr to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 222, in _compute_missing_values_in_feature_mask\n",
            "    _assert_all_finite_element_wise(X, xp=np, allow_nan=True, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: CatBoost ...\n",
            "\t0.9948\t = Validation score   (accuracy)\n",
            "\t92.15s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\tWarning: Exception caused ExtraTreesGini to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 214, in _compute_missing_values_in_feature_mask\n",
            "    assert_all_finite(X, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 213, in assert_all_finite\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\tWarning: Exception caused ExtraTreesEntr to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 214, in _compute_missing_values_in_feature_mask\n",
            "    assert_all_finite(X, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 213, in assert_all_finite\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: XGBoost ...\n",
            "\tWarning: Exception caused XGBoost to fail during training... Skipping this model.\n",
            "\t\t[02:41:22] /workspace/src/data/../common/../data/gradient_index.h:94: Check failed: valid: Input data contains `inf` or a value too large, while `missing` is not set to `inf`\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x22dcbc) [0x7d0770e2dcbc]\n",
            "  [bt] (1) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x52a356) [0x7d077112a356]\n",
            "  [bt] (2) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51b617) [0x7d077111b617]\n",
            "  [bt] (3) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51dbbc) [0x7d077111dbbc]\n",
            "  [bt] (4) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x4cd1ca) [0x7d07710cd1ca]\n",
            "  [bt] (5) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(XGQuantileDMatrixCreateFromCallback+0x18c) [0x7d0770d4556c]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7d089ac32e2e]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7d089ac2f493]\n",
            "  [bt] (8) /usr/lib/python3.11/lib-dynload/_ctypes.cpython-311-x86_64-linux-gnu.so(+0xa4d8) [0x7d089ac584d8]\n",
            "\n",
            "\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 194, in _fit\n",
            "    self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 1512, in fit\n",
            "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 596, in _wrap_evaluation_matrices\n",
            "    train_dmatrix = create_dmatrix(\n",
            "                    ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 1003, in _create_dmatrix\n",
            "    return QuantileDMatrix(\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 1573, in __init__\n",
            "    self._init(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 1634, in _init\n",
            "    _check_call(ret)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 284, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [02:41:22] /workspace/src/data/../common/../data/gradient_index.h:94: Check failed: valid: Input data contains `inf` or a value too large, while `missing` is not set to `inf`\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x22dcbc) [0x7d0770e2dcbc]\n",
            "  [bt] (1) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x52a356) [0x7d077112a356]\n",
            "  [bt] (2) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51b617) [0x7d077111b617]\n",
            "  [bt] (3) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51dbbc) [0x7d077111dbbc]\n",
            "  [bt] (4) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x4cd1ca) [0x7d07710cd1ca]\n",
            "  [bt] (5) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(XGQuantileDMatrixCreateFromCallback+0x18c) [0x7d0770d4556c]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7d089ac32e2e]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7d089ac2f493]\n",
            "  [bt] (8) /usr/lib/python3.11/lib-dynload/_ctypes.cpython-311-x86_64-linux-gnu.so(+0xa4d8) [0x7d089ac584d8]\n",
            "\n",
            "\n",
            "Fitting model: NeuralNetTorch ...\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/core/nanops.py:1256: RuntimeWarning: invalid value encountered in subtract\n",
            "  adjusted = values - mean\n",
            "\tWarning: Exception caused NeuralNetTorch to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float64').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
            "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
            "    dataset = self._process_train_data(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 744, in _process_train_data\n",
            "    df = self.processor.fit_transform(df)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\", line 976, in fit_transform\n",
            "    result = self._call_func_on_transformers(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\", line 885, in _call_func_on_transformers\n",
            "    return Parallel(n_jobs=self.n_jobs)(jobs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 74, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1918, in __call__\n",
            "    return output if self.return_generator else list(output)\n",
            "                                                ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
            "    res = func(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 136, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 533, in fit_transform\n",
            "    Xt = self._fit(X, y, routed_params)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 406, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/memory.py\", line 312, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1098, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 421, in fit\n",
            "    X = self._validate_input(X, in_fit=True)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 350, in _validate_input\n",
            "    raise ve\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 332, in _validate_input\n",
            "    X = self._validate_data(\n",
            "        ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 633, in _validate_data\n",
            "    out = check_array(X, input_name=\"X\", **check_params)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float64').\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.9952\t = Validation score   (accuracy)\n",
            "\t16.56s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'LightGBM': 1.0}\n",
            "\t0.996\t = Validation score   (accuracy)\n",
            "\t0.12s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 192.47s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 47645.0 rows/s (2500 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20250118_023826\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20250118_024139\"\n",
            "Warning: `cache_data=False` will disable or limit advanced functionality after training such as feature importance calculations. It is recommended to set `cache_data=True` unless you explicitly wish to not have the data saved to disk.\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.69 GB / 12.67 GB (84.3%)\n",
            "Disk Space Avail:   75.18 GB / 107.72 GB (69.8%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20250118_024139\"\n",
            "Train Data Rows:    50995\n",
            "Train Data Columns: 77\n",
            "Label Column:       Label\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t7 unique label values:  ['DoS', 'BENIGN', 'PortScan', 'WebAttack', 'BruteForce', 'Bot', 'Infiltration']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9955877162019061\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Data Class Count: 7\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    10956.72 MB\n",
            "\tTrain Data (Original)  Memory Usage: 29.96 MB (0.3% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 8 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tUseless Original Features (Count: 10): ['Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'CWE Flag Count', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 9): ['SYN Flag Count', 'ECE Flag Count', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Header Length.1', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('float', []) : 2 | ['Avg Fwd Segment Size', 'Avg Bwd Segment Size']\n",
            "\t\t('int', [])   : 7 | ['SYN Flag Count', 'ECE Flag Count', 'Fwd Header Length.1', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 22 | ['Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', ...]\n",
            "\t\t('int', [])   : 36 | ['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets', 'Total Length of Bwd Packets', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 22 | ['Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', ...]\n",
            "\t\t('int', [])       : 30 | ['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets', 'Total Length of Bwd Packets', ...]\n",
            "\t\t('int', ['bool']) :  6 | ['Fwd PSH Flags', 'FIN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', ...]\n",
            "\t3.6s = Fit runtime\n",
            "\t58 features in original data used to generate 58 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 20.52 MB (0.2% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 3.83s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.04902441415825081, Train Rows: 48495, Val Rows: 2500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 13 L1 models, fit_strategy=\"parallel\" ...\n",
            "Note: fit_strategy='parallel', but `num_cpus=2`. Running parallel mode with fewer than 12 CPUs is not recommended and has been disabled. You can override this by specifying `os.environ[\"AG_FORCE_PARALLEL\"] = \"True\"`. Falling back to fit_strategy='sequential' ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\tWarning: Exception caused KNeighborsUnif to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/knn/knn_model.py\", line 103, in _fit\n",
            "    self.model = self._get_model_type()(**params).fit(X, y)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py\", line 238, in fit\n",
            "    return self._fit(X, y)\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_base.py\", line 475, in _fit\n",
            "    X, y = self._validate_data(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 650, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n",
            "    X = check_array(\n",
            "        ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: KNeighborsDist ...\n",
            "\tWarning: Exception caused KNeighborsDist to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/knn/knn_model.py\", line 103, in _fit\n",
            "    self.model = self._get_model_type()(**params).fit(X, y)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py\", line 238, in fit\n",
            "    return self._fit(X, y)\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_base.py\", line 475, in _fit\n",
            "    X, y = self._validate_data(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 650, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n",
            "    X = check_array(\n",
            "        ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "No improvement since epoch 0: early stopping\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "\t0.4\t = Validation score   (accuracy)\n",
            "\t46.47s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.9948\t = Validation score   (accuracy)\n",
            "\t16.69s\t = Training   runtime\n",
            "\t0.22s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.996\t = Validation score   (accuracy)\n",
            "\t14.91s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\tWarning: Exception caused RandomForestGini to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 222, in _compute_missing_values_in_feature_mask\n",
            "    _assert_all_finite_element_wise(X, xp=np, allow_nan=True, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: RandomForestEntr ...\n",
            "\tWarning: Exception caused RandomForestEntr to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 222, in _compute_missing_values_in_feature_mask\n",
            "    _assert_all_finite_element_wise(X, xp=np, allow_nan=True, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: CatBoost ...\n",
            "\t0.9948\t = Validation score   (accuracy)\n",
            "\t90.16s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\tWarning: Exception caused ExtraTreesGini to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 214, in _compute_missing_values_in_feature_mask\n",
            "    assert_all_finite(X, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 213, in assert_all_finite\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\tWarning: Exception caused ExtraTreesEntr to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 214, in _compute_missing_values_in_feature_mask\n",
            "    assert_all_finite(X, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 213, in assert_all_finite\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: XGBoost ...\n",
            "\tWarning: Exception caused XGBoost to fail during training... Skipping this model.\n",
            "\t\t[02:44:35] /workspace/src/data/../common/../data/gradient_index.h:94: Check failed: valid: Input data contains `inf` or a value too large, while `missing` is not set to `inf`\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x22dcbc) [0x7d0770e2dcbc]\n",
            "  [bt] (1) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x52a356) [0x7d077112a356]\n",
            "  [bt] (2) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51b617) [0x7d077111b617]\n",
            "  [bt] (3) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51dbbc) [0x7d077111dbbc]\n",
            "  [bt] (4) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x4cd1ca) [0x7d07710cd1ca]\n",
            "  [bt] (5) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(XGQuantileDMatrixCreateFromCallback+0x18c) [0x7d0770d4556c]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7d089ac32e2e]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7d089ac2f493]\n",
            "  [bt] (8) /usr/lib/python3.11/lib-dynload/_ctypes.cpython-311-x86_64-linux-gnu.so(+0xa4d8) [0x7d089ac584d8]\n",
            "\n",
            "\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 194, in _fit\n",
            "    self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 1512, in fit\n",
            "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 596, in _wrap_evaluation_matrices\n",
            "    train_dmatrix = create_dmatrix(\n",
            "                    ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 1003, in _create_dmatrix\n",
            "    return QuantileDMatrix(\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 1573, in __init__\n",
            "    self._init(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 1634, in _init\n",
            "    _check_call(ret)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 284, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [02:44:35] /workspace/src/data/../common/../data/gradient_index.h:94: Check failed: valid: Input data contains `inf` or a value too large, while `missing` is not set to `inf`\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x22dcbc) [0x7d0770e2dcbc]\n",
            "  [bt] (1) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x52a356) [0x7d077112a356]\n",
            "  [bt] (2) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51b617) [0x7d077111b617]\n",
            "  [bt] (3) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51dbbc) [0x7d077111dbbc]\n",
            "  [bt] (4) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x4cd1ca) [0x7d07710cd1ca]\n",
            "  [bt] (5) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(XGQuantileDMatrixCreateFromCallback+0x18c) [0x7d0770d4556c]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7d089ac32e2e]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7d089ac2f493]\n",
            "  [bt] (8) /usr/lib/python3.11/lib-dynload/_ctypes.cpython-311-x86_64-linux-gnu.so(+0xa4d8) [0x7d089ac584d8]\n",
            "\n",
            "\n",
            "Fitting model: NeuralNetTorch ...\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/core/nanops.py:1256: RuntimeWarning: invalid value encountered in subtract\n",
            "  adjusted = values - mean\n",
            "\tWarning: Exception caused NeuralNetTorch to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float64').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
            "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
            "    dataset = self._process_train_data(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 744, in _process_train_data\n",
            "    df = self.processor.fit_transform(df)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\", line 976, in fit_transform\n",
            "    result = self._call_func_on_transformers(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\", line 885, in _call_func_on_transformers\n",
            "    return Parallel(n_jobs=self.n_jobs)(jobs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 74, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1918, in __call__\n",
            "    return output if self.return_generator else list(output)\n",
            "                                                ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
            "    res = func(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 136, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 533, in fit_transform\n",
            "    Xt = self._fit(X, y, routed_params)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 406, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/memory.py\", line 312, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1098, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 421, in fit\n",
            "    X = self._validate_input(X, in_fit=True)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 350, in _validate_input\n",
            "    raise ve\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 332, in _validate_input\n",
            "    X = self._validate_data(\n",
            "        ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 633, in _validate_data\n",
            "    out = check_array(X, input_name=\"X\", **check_params)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float64').\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.9952\t = Validation score   (accuracy)\n",
            "\t19.1s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'LightGBM': 1.0}\n",
            "\t0.996\t = Validation score   (accuracy)\n",
            "\t0.1s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 195.39s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 38463.6 rows/s (2500 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20250118_024139\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20250118_024455\"\n",
            "Warning: `cache_data=False` will disable or limit advanced functionality after training such as feature importance calculations. It is recommended to set `cache_data=True` unless you explicitly wish to not have the data saved to disk.\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.71 GB / 12.67 GB (84.5%)\n",
            "Disk Space Avail:   75.17 GB / 107.72 GB (69.8%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20250118_024455\"\n",
            "Train Data Rows:    50995\n",
            "Train Data Columns: 77\n",
            "Label Column:       Label\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t7 unique label values:  ['DoS', 'BENIGN', 'PortScan', 'WebAttack', 'BruteForce', 'Bot', 'Infiltration']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9955877162019061\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Data Class Count: 7\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    10973.02 MB\n",
            "\tTrain Data (Original)  Memory Usage: 29.96 MB (0.3% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 8 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tUseless Original Features (Count: 10): ['Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'CWE Flag Count', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 9): ['SYN Flag Count', 'ECE Flag Count', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Header Length.1', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('float', []) : 2 | ['Avg Fwd Segment Size', 'Avg Bwd Segment Size']\n",
            "\t\t('int', [])   : 7 | ['SYN Flag Count', 'ECE Flag Count', 'Fwd Header Length.1', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 22 | ['Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', ...]\n",
            "\t\t('int', [])   : 36 | ['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets', 'Total Length of Bwd Packets', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 22 | ['Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', ...]\n",
            "\t\t('int', [])       : 30 | ['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets', 'Total Length of Bwd Packets', ...]\n",
            "\t\t('int', ['bool']) :  6 | ['Fwd PSH Flags', 'FIN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', ...]\n",
            "\t3.0s = Fit runtime\n",
            "\t58 features in original data used to generate 58 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 20.52 MB (0.2% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 3.22s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.04902441415825081, Train Rows: 48495, Val Rows: 2500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 13 L1 models, fit_strategy=\"parallel\" ...\n",
            "Note: fit_strategy='parallel', but `num_cpus=2`. Running parallel mode with fewer than 12 CPUs is not recommended and has been disabled. You can override this by specifying `os.environ[\"AG_FORCE_PARALLEL\"] = \"True\"`. Falling back to fit_strategy='sequential' ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\tWarning: Exception caused KNeighborsUnif to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/knn/knn_model.py\", line 103, in _fit\n",
            "    self.model = self._get_model_type()(**params).fit(X, y)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py\", line 238, in fit\n",
            "    return self._fit(X, y)\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_base.py\", line 475, in _fit\n",
            "    X, y = self._validate_data(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 650, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n",
            "    X = check_array(\n",
            "        ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: KNeighborsDist ...\n",
            "\tWarning: Exception caused KNeighborsDist to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/knn/knn_model.py\", line 103, in _fit\n",
            "    self.model = self._get_model_type()(**params).fit(X, y)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py\", line 238, in fit\n",
            "    return self._fit(X, y)\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_base.py\", line 475, in _fit\n",
            "    X, y = self._validate_data(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 650, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n",
            "    X = check_array(\n",
            "        ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "No improvement since epoch 0: early stopping\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "\t0.4\t = Validation score   (accuracy)\n",
            "\t46.46s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.9948\t = Validation score   (accuracy)\n",
            "\t17.36s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.996\t = Validation score   (accuracy)\n",
            "\t12.9s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\tWarning: Exception caused RandomForestGini to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 222, in _compute_missing_values_in_feature_mask\n",
            "    _assert_all_finite_element_wise(X, xp=np, allow_nan=True, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: RandomForestEntr ...\n",
            "\tWarning: Exception caused RandomForestEntr to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 222, in _compute_missing_values_in_feature_mask\n",
            "    _assert_all_finite_element_wise(X, xp=np, allow_nan=True, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: CatBoost ...\n",
            "\t0.9948\t = Validation score   (accuracy)\n",
            "\t90.81s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\tWarning: Exception caused ExtraTreesGini to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 214, in _compute_missing_values_in_feature_mask\n",
            "    assert_all_finite(X, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 213, in assert_all_finite\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\tWarning: Exception caused ExtraTreesEntr to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 214, in _compute_missing_values_in_feature_mask\n",
            "    assert_all_finite(X, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 213, in assert_all_finite\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: XGBoost ...\n",
            "\tWarning: Exception caused XGBoost to fail during training... Skipping this model.\n",
            "\t\t[02:47:49] /workspace/src/data/../common/../data/gradient_index.h:94: Check failed: valid: Input data contains `inf` or a value too large, while `missing` is not set to `inf`\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x22dcbc) [0x7d0770e2dcbc]\n",
            "  [bt] (1) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x52a356) [0x7d077112a356]\n",
            "  [bt] (2) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51b617) [0x7d077111b617]\n",
            "  [bt] (3) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51dbbc) [0x7d077111dbbc]\n",
            "  [bt] (4) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x4cd1ca) [0x7d07710cd1ca]\n",
            "  [bt] (5) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(XGQuantileDMatrixCreateFromCallback+0x18c) [0x7d0770d4556c]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7d089ac32e2e]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7d089ac2f493]\n",
            "  [bt] (8) /usr/lib/python3.11/lib-dynload/_ctypes.cpython-311-x86_64-linux-gnu.so(+0xa4d8) [0x7d089ac584d8]\n",
            "\n",
            "\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 194, in _fit\n",
            "    self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 1512, in fit\n",
            "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 596, in _wrap_evaluation_matrices\n",
            "    train_dmatrix = create_dmatrix(\n",
            "                    ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 1003, in _create_dmatrix\n",
            "    return QuantileDMatrix(\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 1573, in __init__\n",
            "    self._init(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 1634, in _init\n",
            "    _check_call(ret)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 284, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [02:47:49] /workspace/src/data/../common/../data/gradient_index.h:94: Check failed: valid: Input data contains `inf` or a value too large, while `missing` is not set to `inf`\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x22dcbc) [0x7d0770e2dcbc]\n",
            "  [bt] (1) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x52a356) [0x7d077112a356]\n",
            "  [bt] (2) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51b617) [0x7d077111b617]\n",
            "  [bt] (3) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51dbbc) [0x7d077111dbbc]\n",
            "  [bt] (4) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x4cd1ca) [0x7d07710cd1ca]\n",
            "  [bt] (5) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(XGQuantileDMatrixCreateFromCallback+0x18c) [0x7d0770d4556c]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7d089ac32e2e]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7d089ac2f493]\n",
            "  [bt] (8) /usr/lib/python3.11/lib-dynload/_ctypes.cpython-311-x86_64-linux-gnu.so(+0xa4d8) [0x7d089ac584d8]\n",
            "\n",
            "\n",
            "Fitting model: NeuralNetTorch ...\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/core/nanops.py:1256: RuntimeWarning: invalid value encountered in subtract\n",
            "  adjusted = values - mean\n",
            "\tWarning: Exception caused NeuralNetTorch to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float64').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
            "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
            "    dataset = self._process_train_data(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 744, in _process_train_data\n",
            "    df = self.processor.fit_transform(df)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\", line 976, in fit_transform\n",
            "    result = self._call_func_on_transformers(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\", line 885, in _call_func_on_transformers\n",
            "    return Parallel(n_jobs=self.n_jobs)(jobs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 74, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1918, in __call__\n",
            "    return output if self.return_generator else list(output)\n",
            "                                                ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
            "    res = func(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 136, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 533, in fit_transform\n",
            "    Xt = self._fit(X, y, routed_params)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 406, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/memory.py\", line 312, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1098, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 421, in fit\n",
            "    X = self._validate_input(X, in_fit=True)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 350, in _validate_input\n",
            "    raise ve\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 332, in _validate_input\n",
            "    X = self._validate_data(\n",
            "        ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 633, in _validate_data\n",
            "    out = check_array(X, input_name=\"X\", **check_params)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float64').\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.9952\t = Validation score   (accuracy)\n",
            "\t16.85s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'LightGBM': 1.0}\n",
            "\t0.996\t = Validation score   (accuracy)\n",
            "\t0.1s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 191.83s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 36127.3 rows/s (2500 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20250118_024455\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20250118_024807\"\n",
            "Warning: `cache_data=False` will disable or limit advanced functionality after training such as feature importance calculations. It is recommended to set `cache_data=True` unless you explicitly wish to not have the data saved to disk.\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.71 GB / 12.67 GB (84.5%)\n",
            "Disk Space Avail:   75.16 GB / 107.72 GB (69.8%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20250118_024807\"\n",
            "Train Data Rows:    50995\n",
            "Train Data Columns: 77\n",
            "Label Column:       Label\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t7 unique label values:  ['DoS', 'BENIGN', 'PortScan', 'WebAttack', 'BruteForce', 'Bot', 'Infiltration']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 7\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9955877162019061\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    10983.47 MB\n",
            "\tTrain Data (Original)  Memory Usage: 29.96 MB (0.3% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 8 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tUseless Original Features (Count: 10): ['Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'CWE Flag Count', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 9): ['SYN Flag Count', 'ECE Flag Count', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Header Length.1', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('float', []) : 2 | ['Avg Fwd Segment Size', 'Avg Bwd Segment Size']\n",
            "\t\t('int', [])   : 7 | ['SYN Flag Count', 'ECE Flag Count', 'Fwd Header Length.1', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 22 | ['Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', ...]\n",
            "\t\t('int', [])   : 36 | ['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets', 'Total Length of Bwd Packets', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 22 | ['Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', ...]\n",
            "\t\t('int', [])       : 30 | ['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets', 'Total Length of Bwd Packets', ...]\n",
            "\t\t('int', ['bool']) :  6 | ['Fwd PSH Flags', 'FIN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', ...]\n",
            "\t3.0s = Fit runtime\n",
            "\t58 features in original data used to generate 58 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 20.52 MB (0.2% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 3.17s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.04902441415825081, Train Rows: 48495, Val Rows: 2500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 13 L1 models, fit_strategy=\"parallel\" ...\n",
            "Note: fit_strategy='parallel', but `num_cpus=2`. Running parallel mode with fewer than 12 CPUs is not recommended and has been disabled. You can override this by specifying `os.environ[\"AG_FORCE_PARALLEL\"] = \"True\"`. Falling back to fit_strategy='sequential' ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\tWarning: Exception caused KNeighborsUnif to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/knn/knn_model.py\", line 103, in _fit\n",
            "    self.model = self._get_model_type()(**params).fit(X, y)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py\", line 238, in fit\n",
            "    return self._fit(X, y)\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_base.py\", line 475, in _fit\n",
            "    X, y = self._validate_data(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 650, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n",
            "    X = check_array(\n",
            "        ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: KNeighborsDist ...\n",
            "\tWarning: Exception caused KNeighborsDist to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/knn/knn_model.py\", line 103, in _fit\n",
            "    self.model = self._get_model_type()(**params).fit(X, y)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py\", line 238, in fit\n",
            "    return self._fit(X, y)\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_base.py\", line 475, in _fit\n",
            "    X, y = self._validate_data(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 650, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n",
            "    X = check_array(\n",
            "        ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "No improvement since epoch 0: early stopping\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "\t0.4\t = Validation score   (accuracy)\n",
            "\t45.49s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.9948\t = Validation score   (accuracy)\n",
            "\t16.83s\t = Training   runtime\n",
            "\t0.22s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.996\t = Validation score   (accuracy)\n",
            "\t12.19s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\tWarning: Exception caused RandomForestGini to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 222, in _compute_missing_values_in_feature_mask\n",
            "    _assert_all_finite_element_wise(X, xp=np, allow_nan=True, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: RandomForestEntr ...\n",
            "\tWarning: Exception caused RandomForestEntr to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 222, in _compute_missing_values_in_feature_mask\n",
            "    _assert_all_finite_element_wise(X, xp=np, allow_nan=True, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: CatBoost ...\n",
            "\t0.9948\t = Validation score   (accuracy)\n",
            "\t91.28s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\tWarning: Exception caused ExtraTreesGini to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 214, in _compute_missing_values_in_feature_mask\n",
            "    assert_all_finite(X, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 213, in assert_all_finite\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\tWarning: Exception caused ExtraTreesEntr to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 214, in _compute_missing_values_in_feature_mask\n",
            "    assert_all_finite(X, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 213, in assert_all_finite\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: XGBoost ...\n",
            "\tWarning: Exception caused XGBoost to fail during training... Skipping this model.\n",
            "\t\t[02:50:59] /workspace/src/data/../common/../data/gradient_index.h:94: Check failed: valid: Input data contains `inf` or a value too large, while `missing` is not set to `inf`\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x22dcbc) [0x7d0770e2dcbc]\n",
            "  [bt] (1) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x52a356) [0x7d077112a356]\n",
            "  [bt] (2) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51b617) [0x7d077111b617]\n",
            "  [bt] (3) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51dbbc) [0x7d077111dbbc]\n",
            "  [bt] (4) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x4cd1ca) [0x7d07710cd1ca]\n",
            "  [bt] (5) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(XGQuantileDMatrixCreateFromCallback+0x18c) [0x7d0770d4556c]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7d089ac32e2e]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7d089ac2f493]\n",
            "  [bt] (8) /usr/lib/python3.11/lib-dynload/_ctypes.cpython-311-x86_64-linux-gnu.so(+0xa4d8) [0x7d089ac584d8]\n",
            "\n",
            "\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 194, in _fit\n",
            "    self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 1512, in fit\n",
            "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 596, in _wrap_evaluation_matrices\n",
            "    train_dmatrix = create_dmatrix(\n",
            "                    ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 1003, in _create_dmatrix\n",
            "    return QuantileDMatrix(\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 1573, in __init__\n",
            "    self._init(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 1634, in _init\n",
            "    _check_call(ret)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 284, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [02:50:59] /workspace/src/data/../common/../data/gradient_index.h:94: Check failed: valid: Input data contains `inf` or a value too large, while `missing` is not set to `inf`\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x22dcbc) [0x7d0770e2dcbc]\n",
            "  [bt] (1) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x52a356) [0x7d077112a356]\n",
            "  [bt] (2) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51b617) [0x7d077111b617]\n",
            "  [bt] (3) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51dbbc) [0x7d077111dbbc]\n",
            "  [bt] (4) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x4cd1ca) [0x7d07710cd1ca]\n",
            "  [bt] (5) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(XGQuantileDMatrixCreateFromCallback+0x18c) [0x7d0770d4556c]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7d089ac32e2e]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7d089ac2f493]\n",
            "  [bt] (8) /usr/lib/python3.11/lib-dynload/_ctypes.cpython-311-x86_64-linux-gnu.so(+0xa4d8) [0x7d089ac584d8]\n",
            "\n",
            "\n",
            "Fitting model: NeuralNetTorch ...\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/core/nanops.py:1256: RuntimeWarning: invalid value encountered in subtract\n",
            "  adjusted = values - mean\n",
            "\tWarning: Exception caused NeuralNetTorch to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float64').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
            "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
            "    dataset = self._process_train_data(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 744, in _process_train_data\n",
            "    df = self.processor.fit_transform(df)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\", line 976, in fit_transform\n",
            "    result = self._call_func_on_transformers(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\", line 885, in _call_func_on_transformers\n",
            "    return Parallel(n_jobs=self.n_jobs)(jobs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 74, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1918, in __call__\n",
            "    return output if self.return_generator else list(output)\n",
            "                                                ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
            "    res = func(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 136, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 533, in fit_transform\n",
            "    Xt = self._fit(X, y, routed_params)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 406, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/memory.py\", line 312, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1098, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 421, in fit\n",
            "    X = self._validate_input(X, in_fit=True)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 350, in _validate_input\n",
            "    raise ve\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 332, in _validate_input\n",
            "    X = self._validate_data(\n",
            "        ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 633, in _validate_data\n",
            "    out = check_array(X, input_name=\"X\", **check_params)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float64').\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.9952\t = Validation score   (accuracy)\n",
            "\t16.01s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'LightGBM': 1.0}\n",
            "\t0.996\t = Validation score   (accuracy)\n",
            "\t0.1s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 189.1s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 40283.8 rows/s (2500 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20250118_024807\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20250118_025116\"\n",
            "Warning: `cache_data=False` will disable or limit advanced functionality after training such as feature importance calculations. It is recommended to set `cache_data=True` unless you explicitly wish to not have the data saved to disk.\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.69 GB / 12.67 GB (84.3%)\n",
            "Disk Space Avail:   75.15 GB / 107.72 GB (69.8%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20250118_025116\"\n",
            "Train Data Rows:    50995\n",
            "Train Data Columns: 77\n",
            "Label Column:       Label\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t7 unique label values:  ['DoS', 'BENIGN', 'PortScan', 'WebAttack', 'BruteForce', 'Bot', 'Infiltration']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9955877162019061\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Data Class Count: 7\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    10976.88 MB\n",
            "\tTrain Data (Original)  Memory Usage: 29.96 MB (0.3% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 8 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tUseless Original Features (Count: 10): ['Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'CWE Flag Count', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 9): ['SYN Flag Count', 'ECE Flag Count', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Header Length.1', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('float', []) : 2 | ['Avg Fwd Segment Size', 'Avg Bwd Segment Size']\n",
            "\t\t('int', [])   : 7 | ['SYN Flag Count', 'ECE Flag Count', 'Fwd Header Length.1', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 22 | ['Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', ...]\n",
            "\t\t('int', [])   : 36 | ['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets', 'Total Length of Bwd Packets', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 22 | ['Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', ...]\n",
            "\t\t('int', [])       : 30 | ['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets', 'Total Length of Bwd Packets', ...]\n",
            "\t\t('int', ['bool']) :  6 | ['Fwd PSH Flags', 'FIN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', ...]\n",
            "\t4.2s = Fit runtime\n",
            "\t58 features in original data used to generate 58 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 20.52 MB (0.2% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 4.37s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.04902441415825081, Train Rows: 48495, Val Rows: 2500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 13 L1 models, fit_strategy=\"parallel\" ...\n",
            "Note: fit_strategy='parallel', but `num_cpus=2`. Running parallel mode with fewer than 12 CPUs is not recommended and has been disabled. You can override this by specifying `os.environ[\"AG_FORCE_PARALLEL\"] = \"True\"`. Falling back to fit_strategy='sequential' ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\tWarning: Exception caused KNeighborsUnif to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/knn/knn_model.py\", line 103, in _fit\n",
            "    self.model = self._get_model_type()(**params).fit(X, y)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py\", line 238, in fit\n",
            "    return self._fit(X, y)\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_base.py\", line 475, in _fit\n",
            "    X, y = self._validate_data(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 650, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n",
            "    X = check_array(\n",
            "        ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: KNeighborsDist ...\n",
            "\tWarning: Exception caused KNeighborsDist to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/knn/knn_model.py\", line 103, in _fit\n",
            "    self.model = self._get_model_type()(**params).fit(X, y)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py\", line 238, in fit\n",
            "    return self._fit(X, y)\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_base.py\", line 475, in _fit\n",
            "    X, y = self._validate_data(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 650, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n",
            "    X = check_array(\n",
            "        ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "No improvement since epoch 0: early stopping\n",
            "/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:188: RuntimeWarning: invalid value encountered in subtract\n",
            "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
            "\t0.4\t = Validation score   (accuracy)\n",
            "\t44.28s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.9948\t = Validation score   (accuracy)\n",
            "\t17.5s\t = Training   runtime\n",
            "\t0.18s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.996\t = Validation score   (accuracy)\n",
            "\t12.88s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\tWarning: Exception caused RandomForestGini to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 222, in _compute_missing_values_in_feature_mask\n",
            "    _assert_all_finite_element_wise(X, xp=np, allow_nan=True, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: RandomForestEntr ...\n",
            "\tWarning: Exception caused RandomForestEntr to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 222, in _compute_missing_values_in_feature_mask\n",
            "    _assert_all_finite_element_wise(X, xp=np, allow_nan=True, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: CatBoost ...\n",
            "\t0.9948\t = Validation score   (accuracy)\n",
            "\t92.13s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\tWarning: Exception caused ExtraTreesGini to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 214, in _compute_missing_values_in_feature_mask\n",
            "    assert_all_finite(X, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 213, in assert_all_finite\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\tWarning: Exception caused ExtraTreesEntr to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/rf/rf_model.py\", line 214, in _fit\n",
            "    model = model.fit(X, y, sample_weight=sample_weight)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 377, in fit\n",
            "    estimator._compute_missing_values_in_feature_mask(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 214, in _compute_missing_values_in_feature_mask\n",
            "    assert_all_finite(X, **common_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 213, in assert_all_finite\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
            "Fitting model: XGBoost ...\n",
            "\tWarning: Exception caused XGBoost to fail during training... Skipping this model.\n",
            "\t\t[02:54:11] /workspace/src/data/../common/../data/gradient_index.h:94: Check failed: valid: Input data contains `inf` or a value too large, while `missing` is not set to `inf`\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x22dcbc) [0x7d0770e2dcbc]\n",
            "  [bt] (1) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x52a356) [0x7d077112a356]\n",
            "  [bt] (2) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51b617) [0x7d077111b617]\n",
            "  [bt] (3) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51dbbc) [0x7d077111dbbc]\n",
            "  [bt] (4) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x4cd1ca) [0x7d07710cd1ca]\n",
            "  [bt] (5) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(XGQuantileDMatrixCreateFromCallback+0x18c) [0x7d0770d4556c]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7d089ac32e2e]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7d089ac2f493]\n",
            "  [bt] (8) /usr/lib/python3.11/lib-dynload/_ctypes.cpython-311-x86_64-linux-gnu.so(+0xa4d8) [0x7d089ac584d8]\n",
            "\n",
            "\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 194, in _fit\n",
            "    self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 1512, in fit\n",
            "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 596, in _wrap_evaluation_matrices\n",
            "    train_dmatrix = create_dmatrix(\n",
            "                    ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 1003, in _create_dmatrix\n",
            "    return QuantileDMatrix(\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 1573, in __init__\n",
            "    self._init(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 1634, in _init\n",
            "    _check_call(ret)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 284, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [02:54:11] /workspace/src/data/../common/../data/gradient_index.h:94: Check failed: valid: Input data contains `inf` or a value too large, while `missing` is not set to `inf`\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x22dcbc) [0x7d0770e2dcbc]\n",
            "  [bt] (1) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x52a356) [0x7d077112a356]\n",
            "  [bt] (2) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51b617) [0x7d077111b617]\n",
            "  [bt] (3) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x51dbbc) [0x7d077111dbbc]\n",
            "  [bt] (4) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x4cd1ca) [0x7d07710cd1ca]\n",
            "  [bt] (5) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(XGQuantileDMatrixCreateFromCallback+0x18c) [0x7d0770d4556c]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7d089ac32e2e]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7d089ac2f493]\n",
            "  [bt] (8) /usr/lib/python3.11/lib-dynload/_ctypes.cpython-311-x86_64-linux-gnu.so(+0xa4d8) [0x7d089ac584d8]\n",
            "\n",
            "\n",
            "Fitting model: NeuralNetTorch ...\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/core/nanops.py:1256: RuntimeWarning: invalid value encountered in subtract\n",
            "  adjusted = values - mean\n",
            "\tWarning: Exception caused NeuralNetTorch to fail during training... Skipping this model.\n",
            "\t\tInput X contains infinity or a value too large for dtype('float64').\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
            "    model = self._train_single(**model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
            "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
            "    dataset = self._process_train_data(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 744, in _process_train_data\n",
            "    df = self.processor.fit_transform(df)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\", line 976, in fit_transform\n",
            "    result = self._call_func_on_transformers(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\", line 885, in _call_func_on_transformers\n",
            "    return Parallel(n_jobs=self.n_jobs)(jobs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 74, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1918, in __call__\n",
            "    return output if self.return_generator else list(output)\n",
            "                                                ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
            "    res = func(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 136, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 533, in fit_transform\n",
            "    Xt = self._fit(X, y, routed_params)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 406, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/memory.py\", line 312, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1098, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 421, in fit\n",
            "    X = self._validate_input(X, in_fit=True)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 350, in _validate_input\n",
            "    raise ve\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py\", line 332, in _validate_input\n",
            "    X = self._validate_data(\n",
            "        ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 633, in _validate_data\n",
            "    out = check_array(X, input_name=\"X\", **check_params)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains infinity or a value too large for dtype('float64').\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.9952\t = Validation score   (accuracy)\n",
            "\t15.96s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'LightGBM': 1.0}\n",
            "\t0.996\t = Validation score   (accuracy)\n",
            "\t0.1s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 190.92s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 49014.0 rows/s (2500 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20250118_025116\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9955877162019061\n",
            "average: 0.9957995058242146\n"
          ]
        }
      ],
      "source": [
        "# repeatedly taking new test and train sets and\n",
        "# training a different predictor for each and averaging accuracy\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "def train_test_on_new():\n",
        "  train_data = data.sample(frac=0.9, random_state=random.randint(0, 1000))\n",
        "  test_data = data.drop(train_data.index)\n",
        "  predictor = TabularPredictor(label='Label', learner_kwargs={\"cache_data\": False}).fit(train_data=train_data, fit_strategy='parallel')\n",
        "  return predictor.evaluate(test_data)['accuracy']\n",
        "\n",
        "results = []\n",
        "for i in range(10):\n",
        "  result = train_test_on_new()\n",
        "  print(result)\n",
        "  results.append(result)\n",
        "\n",
        "average = sum(results) / len(results)\n",
        "print(f\"average: {average}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynE2UWVPoKGg",
        "outputId": "9a186541-ffa4-4cd3-9dcb-b695e707ea1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9977056124249912, 0.9955877162019061, 0.9955877162019061, 0.9955877162019061, 0.9955877162019061, 0.9955877162019061, 0.9955877162019061, 0.9955877162019061, 0.9955877162019061, 0.9955877162019061]\n"
          ]
        }
      ],
      "source": [
        "print(results)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
